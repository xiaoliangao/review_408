# 第一章 计算机系统概述

## 1.1 计算机硬件的基本组成

### 冯·诺依曼机

- “存储程序”概念

将程序包含的所有指令都预先存储在计算机中，并只给出第一条指令所在的存储位置，让计算机自动顺序执行。

- 冯·诺依曼结构

![image-20220709181152314](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x01%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/image-20220709181152314.png)

- 以运算器为核心。输入的数据哪怕不需要运算器执行运算，也需要经由运算器中转才能送入存储器或输出设备。
- 控制器控制所有组成部件，各部件也会将信息反馈给控制器。
- 冯·诺依曼计算机的特点
- 计算机由五大部件组成：输入设备、输出设备、运算器、存储器、控制器
- 指令和数据以同等地位存于存储器，可按地址寻访
- 指令和数据用二进制表示
- 指令由操作码和地址码组成
- 存储程序
- **以运算器为中心**

### 现代计算机结构

- 现代计算机结构

![image-20220709181946654](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x01%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/image-20220709181946654.png)

- 现代计算机结构特点
- **以存储器为中心**
- CPU=运算器+控制器
- 存储器又称为主存，即通常说的内存/运行内存；而机械硬盘、固态硬盘等不是主存，而是辅存，归为I/O设备
- ![image-20220709182159770](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x01%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/image-20220709182159770.png)

## 1.2 主机中的各硬件部件概述

### 主存储器

- 存储体

存储数据，按地址存储。

- 存储元：存储二进制的电子元件，每个存储元可存1bit
- 存储单元：每个存储单元存放一串二进制代码
- 存储字长：单个存储单元中存储的二进制代码的位数（8bit的整数倍）
- 存储字：存储单元中二进制代码的组合
- 地址寄存器（Memory Address Register）
- 存储数据存放的地址，其**位数反映了存储体中存储单元的个数**。
- 数据寄存器（Memory Data Register）
- 存储要存取的数据，其**位数反映了存储字长。**

### 运算器

- 累加计数器（ACC）：存放操作数、运算的结果
- 乘商寄存器（MQ）：进行乘、除法时使用
- 通用寄存器（X）：存放操作数
- 算术逻辑单元（ALU）：用电路实现各种算术运算、逻辑运算

### 控制器

- 控制单元（Control Unit, CU）
- 分析指令，给出控制信号
- 指令寄存器（Instruction Register, IR）
- 存放当前执行的指令
- 程序计数器（Program Counter, PC）
- 存放下一条指令的地址，有自动加1功能

### 计算机的工作过程

```
int a = 2, b = 3, c = 1, y = 0;
void main(){
    y = a * b + c;
}
```

![image-20220709211014682](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x01%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/image-20220709211014682.png)

*以下操作描述中的小括号“()”表示其中存储的内容，如`(PC)`指的是PC中存储的内容；M（MAR）中的M表示主存储器，M（MAR）表示MAR中存储的地址所对应的存放在主存储器的那一条数据/指令

- 初始状态：(PC)=0，即第一条指令的存储地址
- step 1：（PC）→MAR，使得（MAR）=0
- step 2：M（MAR）→MDR，使得（MDR）= 000001 0000000101
- step 3：取出的是指令，因此需要送到指令寄存器。（MDR）→IR，使得（IR）= 000001 0000000101
- step 4：OP（IR）→CU，即将指令中的**操作码**部分送入控制单元，控制单元分析知`000001`是取数指令，要按地址码指明的地址从主存储器中取数并送入ACC.
- step 5：AD（IR）→MAR，即将指令中的**地址码**送入MAR，使得（MAR）=5（0000000101）。表明取数是从主存储器上的这个地址取数。
- step 6：M（MAR）→MDR，使得（MDR）=0000000000000010=2。按地址从主存储器中取得对应的数。
- step 7：MDR→ACC，使得（ACC）=2。送入到ACC
- step 8：PC自动+1，使得（PC）=1

## 1.3 计算机系统的层次结构

#### 微程序机器 M0

由硬件执行微指令。微指令中特定位的二进制数对应特定电路逻辑门的开关。

一条微指令可实现如存储器读、写等硬件操作。

#### 传统机器 M1

使用机器语言。一条机器语言指令即一段微程序，由多条微指令组成。

如取数指令000001 0000000101，功能为从主存储器的指定地址中取数并送入ACC，则可能包括读入地址码+存储器读+送入总线+ACC写等多条微指令。

#### 虚拟机器/操作系统机器 M2

向上层提供“广义指令”（系统调用）

#### 虚拟机器/汇编语言机器 M3

**汇编语言指令与机器语言指令是一一对应的**，只不过用人类可以看懂的字母符号（助记符）代替了二进制数。

如汇编语言指令`LOAD 5`对应的即机器语言取数指令000001 0000000101。

程序员使用汇编语言编写程序后，再通过汇编程序转换为对应的机器语言，才会被计算机识别执行。

#### 虚拟机器/高级语言机器 M4

与汇编语言相比更加可读，如一行高级语言代码`y=a*b+c`，需要编写前文图中所示的多条汇编语言指令/机器指令才能等效实现。

程序员使用高级语言编写程序后，需要通过**编译程序**（编译器）来将高级语言转换成汇编语言，再经过**汇编程序**最终翻译成计算机可识别可执行的机器语言。

有些编译程序可以直接完成高级语言→机器语言的转换。

另外，还有常见的高级语言如Python、JavaScript等，不通过编译程序进行翻译，而是通过解释程序（解释器）完成高级语言→机器语言的转换。

编译程序和解释程序的异同：

- 编译程序将源程序一次性全部翻译好再执行机器语言程序，只需翻译一次
- 解释程序一次只翻译源程序的一条语句并立即执行，然后再翻译下一条语句。

## 1.4 计算机的性能指标

### 存储器的性能指标

- 总容量
- 存储单元个数×存储字长，单位是bit
- 存储单元个数×存储字长/8，单位是Byte
- 若MAR为32位，MDR为8位，则总容量为$2^{32}\times8 （bit）=4\times2^{30}（Byte）=4GB$
- $1KB=2^{10}Byte$，$1MB=2^{20}Byte$，$1GB=2^{30}Byte$，$1TB=2^{40}Byte$

### CPU的性能指标

- CPU时钟周期：CPU内一个完整数字脉冲所需的时间。单位：微秒或纳秒。
- CPU主频：CPU内数字脉冲信号振荡的频率，即数电中的时钟频率，为CPU时钟周期的倒数。单位：赫兹Hz（注意，GHZ代表$10^9$赫兹）
- CPI（Clock cycle Per Instruction）：执行一条机器指令所需的时钟周期数。

执行一条机器指令所需的时钟周期数是波动的，不同的机器指令会需要不同的时钟周期数，同一条机器指令两次执行所需的时钟周期数也可能不同，这是受其他部件及机器状态影响的。

因此CPI代表的是一个平均值。

- IPS（Instructions Per Second）：每秒执行多少条指令。

 $IPS=\frac{主频}{平均CPI}$

- FLOPS（Floating-point Operations Per Second）：每秒执行浮点运算的次数

### 系统总体的性能指标

- 数据通路带宽：数据总线一次所能并行传送的信息位数
- 吞吐量：系统在单位时间内处理请求的数量
- 响应时间：从用户向计算机发送一个请求到计算机响应并反馈结果的时间

### 常用数量单位

- 描述存储容量、文件大小时：$K=2^{10}$，$M=2^{20}$，$G=2^{30}$，$T=2^{40}$
- 描述频率、速率时：$K=10^{3}$，$M=10^{6}$，$G=10^{9}$，$T=10^{12}$

## 1.5 概念辨析

- **字节、字、字长、机器字长、指令字长、存储字长的区别和联系**

字节：1字节=8bit

字：表示机器中被处理信息的单位。计算机中总线一般被设计为可以传送一块固定大小的数据，每一块数据就是一个字（CS:APP）；或CPU内部用于整数运算的数据通路的宽度，也是寄存器大小（王道/stackoverflow）

字长：一个字所占的bit数。不同机器的字长可能不同，如32位机器的字长为32bit，64位机器的字长为64bit

机器字长：即字长

指令字长：一条机器指令所占的bit数，指令字长取决于操作码的长度、操作数地址的长度和操作数地址的个数，因此不同指令的指令字长可能不同。

存储字长：一个存储单元存储的bit数。

字长/机器字长、指令字长、存储字长都一定是8bit的整数倍，所以能以byte为单位描述

另，指令字长一般是存储字长的整数倍

# 第二章 数据的表示和计算

## 2.1 定点数的表示

定点数即小数点位置固定。如一个8位的存储单元，规定右边数起第2位为小数点所在位，则存储的二进制数必然是`xxxxxx.x`的形式。若直接转换成十进制，则可表示的最大值为63.5（`111111.1`），最小值为0.0。

### 无符号数的表示

无符号数即整个机器字长的全部二进制位均为数值位，没有符号位，相当于数的绝对值。

对于8位二进制，视为无符号数，则对应的十进制数有$2^8=256$种，最小值为0（`0000 0000`），最大值为$2^8-1=255$（`1111 1111`）。

无符号数必然是非负整数，没有无符号小数的说法。

### 有符号数的定点表示

有符号数即专门指定了一个位（最高位）来存储并表示正负号，从而可以表示负数。

有符号数的定点表示方式有原码、反码、补码、移码等方式。

注意，虽然以上表示方式都可以表示负数，但采用的方法是不同的：如原码用最高位的0/1直接表示数的正/负，而补码是将最高位的权值视为负数

#### 原码

- 定点整数的原码

以8位二进制为例，最高位为符号位（0为正，1为负），所定的小数点视为隐含在最低位的右侧（也就是不占位置）。如`1000 0001`即-1，`0000 0005`即+5.

在这种规则下，0有两种表示方式，即`1000 0000`和`0000 0000`

范围：对于8位二进制，最大值127（`0111 1111`），最小值-127（`1111 1111`）

- 定点小数的原码

最高位为符号位（0为正，1为负），所定的小数点视为隐含在符号位的右侧（但不占位置）。也就是说，二进制定点小数转换为十进制后都是`0.xxxxx...`

如`1100 0000`即-0.5，`0110 0000`即+0.75

范围：对于8位二进制，最大值+0.9921875（`0111 1111`），最小值-0.9921875（`1111 1111`）

简单推导：可表示的最大值加上最低位所代表的权值后一定等于1，因此最大值=1-最低位所代表的权值；可表示的最小值即最大值的相反数

#### 反码

反码根据原码得到。

- 若原码的符号位为0，则反码与原码相同
- 若原码的符号位为1，则将原码的数值位全部取反即得到反码。

eg：

- x=+19，$[x]_原=0001 0011$，$[x]_反=0001 0011$
- x=-19，$[x]_原=1001 0011$，$[x]_反=1110 1100$

反码只是原码转换到补码的一个中间状态，实际中很少应用。

#### 补码

原码表示正负数虽然直观，但用原码进行加法运算无法直接得到正确结果；而补码得益于其特殊的表示方法，解决了这一问题。

补码不再直接将最高位用于正负号表示，而是给予一个负的权值。

与无符号数相比较，在8位无符号数中，最高位的权值为$2^7$；而在8位补码（定点整数）中，最高位的权值为$-2^7$。同理，若用于表示定点小数，则最高位的权值为$-2^0$。

举个例子，-1的8位补码表示为`1111 1111`，即$-2^7+2^6+2^5+2^4+2^3+2^2+2^1+2^0$。

这种规则下，0只有一种表示方式，即`0000 0000`

- 原码转换为补码
- 若原码为正数（这里我们把+0排除在外），则补码与原码相同
- 若原码为负数（这里我们把-0排除在外），则将原码转换为反码后末位+1即得到补码。
- 补码转换为原码：方法与上述一致。
- 定点整数的补码
- 最大值：$2^8-1=255$（`0111 1111`）
- 最小值：$-2^8=-256$（`1000 0000`）
- 定点小数的补码
- 最大值：$1-2^{-7}$（`0111 1111`）
- 最小值：$-1$（1000 0000）

#### 移码

移码根据补码得到。直接对（整数）补码的符号位取反就得到移码。

移码的符号位含义与补码相反，1表示正数，0表示负数。且移码只能用于表示整数。

移码的特点是，随着移码所表示的实际数值的增大，其二进制表示直观上（也就是当作无符号数来看）也是增大的。这使得移码之间可以直接按位比较大小，不需要额外进行运算。

## 2.2 定点数的运算

### 符号扩展

如8位二进制数扩展为16位二进制数。

- 对于正整数，其原码、反码、补码表示都是一样的，扩展只需在高位补0
- 对于负整数
- 原码：符号位保持在最高位，在数值位的高位补0
- 反码：符号位保持在最高位，在数值位的高位补1
- 补码：与反码相同（因为补码中右起第一个1往左的部分总是与反码一致）
- 对于正小数，为使权值不变，应在低位补0
- 对于负小数
- 原码：低位补0
- 反码：低位补1
- 补码：与原码相同，低位补0（因为补码中右起第一个1往右的部分总是与原码一致）

### 数据的存储和排列

- 大端模式：内存的低地址存储数据的高字节，符合阅读习惯
- 小端模式：内存的低地址存储数据的低字节，便于机器处理（因为机器读取是从内存低地址开始往高地址读的）

### 边界对齐

计算机按字节编址，一个字节对应一个地址

通常支持按字、按半字、按字节寻址

假设访存每次读/写1个字，若数据按边界不对齐方式进行存储，则数据可能跨越边界，导致机器需要访存两次才能拼接出完整的数据。

边界对齐方式可能会浪费一些空间，但能保证每次读数据都只需要1次访存。

### 移位运算

- 算数移位

符号位保持不变，仅对数值位进行移位。

- 对于原码：右移时高位补0，左移时低位补0.
- 对于反码：右移时高位补符号位的值，左移时低位补符号位的值。
- 对于补码：**对于正数，补位方式与原码相同**；**对于负数**，由于负数的补码来源是反码取反+1，+1操作导致从最低位开始连续的1会全部翻转成0，最后将碰到的第一个0翻转为1，因此负数的补码在形式上，以碰到的第一个0为界，左侧部分实质与反码一致，右侧（包括它自己）与原码一致。所以**在右移补位时，遵循反码的规则高位补1；在左移补位时，遵循原码的规则低位补0**.

在比较简单的情况下可以用左移右移代替乘2和除以2的操作。但右移必定导致精度丢失。

如7（0111），除以2应得3.5，用右移一位来代替只能得到3（0011），与真实值3.5相比不够精确。

- 逻辑移位

把整一个二进制数看作无符号数，整体移位。无论左移右移都补0。

- 循环移位

用于大端存储、小端存储之间的转换。

### 加减运算和溢出判断

#### 加减运算

补码的特性就是在进行加减运算时不必单独考虑符号位如何处理，可以带着符号位一起整体进行运算。

> 设机器字长为8位（含1位符号位），$A=15，B=-24，$求$[A+B]_补$和$[A-B]_补$

解：

$A_补 = 00001111， B_补 = 11101000$，直接按位相加得$[A+B]_补=11110111$

$[-B]_补=00011000$，直接按位相加得$[A-B]_补=00100111$

#### 加减运算器

无符号整数的加减法和补码加减法可以用同一个电路实现，但溢出判断不一样

OF：用于判断有符号数运算是否发生溢出，**只对有符号数加减法有意义**，与无符号数无关。

- 计算方法：OF=最高位产生的**进位** 异或 次高位产生的**进位**
- 进行无符号数加减法时，OF=1，加减法是否溢出？（否，OF位只对有符号数加减法有意义）

CF：用于判断无符号数的加减法是否发生了进位或借位（即溢出）

- 计算方法：最高位产生的进位 异或 sub（若是减法则sub=1，若是加法则sub=0）
- **只对无符号数加减法有意义**

#### 溢出判断

- 上溢和下溢

- 只有”正数+正数“的时候才会上溢，上溢的表现为”正+正=负“（因为进位进到符号位里去了）

- 只有”负数+负数“的时候才会下溢，下溢的表现为”负+负=正“

- 判断方法

- 方法一：采用一位符号位，对运算前和运算后的符号位进行逻辑判断.设$A$的符号位为$A_S$，$B$的符号位为$B_S$，运算结果的符号为$S_S$，溢出判断符号为$V$，无溢出时$V=0$，有溢出时$V=1$，则真值表如下：

  | $A_S$ | $B_S$ | $S_S$ | $V$  |
  | :---- | :---- | :---- | :--- |
  | 0     | 0     | 1     | 1    |
  | 1     | 1     | 0     | 1    |
  | ...   | ...   | ...   | 0    |

  逻辑表达式即$V=A_SB_S\overline{S_S}+\overline{A_S}\overline{B_S}S_S$

- 方法二：采用双符号位。正常情况下正数符号位为$00$，负数符号位为$11$。发生上溢时运算结果符号位为$01$，发生下溢时运算结果符号位为$10$，即符号位两位数值相异则一定有溢出。做异或运算即可判断。

### 乘法运算和溢出判断

#### 乘法

回忆一下十进制的竖式乘法，其实质是把乘数按位权拆开后再逐位与被乘数相乘，最后相加。二进制的竖式乘法同理，且比十进制更简单。将乘数按位权拆开后，若某位为0，则与被乘数相乘后所得的必为全0；若某位为1，则与被乘数相乘后得到被乘数本身。

- 机器实现二进制乘法需要解决的问题
- 如何处理符号位
- 最终结果的位数是两个乘数位数之和，如果超出了寄存器一次能保存下来的位数，如何处理？
- 如何把所有乘积保存下来再统一相加
- 原码一位乘法
- 如何处理符号位：符号位异或运算得到运算结果的符号位
- 如何处理位数翻倍：两个寄存器，ACC存放乘积高位，MQ存放乘积低位
- 如何相加:一边乘一边加

> 设机器字长为5位（含1位符号位），$[x]_原=1.1101，[y]_原=0.1011$，采用原码一位乘法求$x\times y$

- 初始：ACC清零，(ACC)=00000，(X)=01101，(MQ)=01011。MQ中参与乘法运算的位始终是MQ的最低位。

- # 1：MQ最低位为1，所以让ACC加上(X)，(ACC)=01101

- # 2：ACC和MQ同时逻辑右移一位，(ACC)=00110，

   原最低位上的1移到MQ的最高位，(MQ)=10101；

   MQ最低位为1，所以让ACC加上（X），(ACC)=10011

- # 3：ACC和MQ同时逻辑右移一位，(ACC)=01001，

   原最低位上的1移到MQ的最高位，(MQ)=11010；

   MQ最低位为0，所以让ACC加上0，(ACC)=01001

- # 4：ACC和MQ同时逻辑右移一位，(ACC)=00100，

   原最低位上的1移到MQ的最高位，(MQ)=11101；

   MQ最低位为1，所以让ACC加上(X)，(ACC)=10001

- # 5：ACC和MQ同时逻辑右移一位，(ACC)=01000，

   原最低位上的1移到MQ的最高位，(MQ)=11110；

   MQ最低位为0，所以让ACC加上0，(ACC)=01000

- # 6：至此MQ上原二进制数的各位都已计算完毕，又乘积的符号位应为1，故（ACC）=11000。

- (ACC)=11000是**乘积的高位部分**，(MQ)=11110中的**下划线部分是乘积的低位部分**，因此得到最终乘积为1.10001111

#### 无符号数乘法运算电路结构

![IMG_0750(20221205-212706)](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x02%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AE%A1%E7%AE%97/IMG_0750%2820221205-212706%29-1670246905054.PNG)

控制逻辑&计数器：

- 用于发出“加法、右移、写使能”的控制信号，检查当前**乘积寄存器**（即高四位）中末位是0还是1，若为1则执行加法（高四位与被乘数相加）然后右移，否则直接右移；
- 计数器用于记录加法、右移次数
- 写使能信号用于控制乘积寄存器P，使ALU将结果写入P

加法是无符号数加法，右移是**逻辑右移**。

溢出判断：

- 若乘积寄存器（即高四位）为全0，则未溢出
- 否则溢出

#### 有符号数乘法运算电路结构

![IMG_0749(20221205-212647)](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x02%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AE%A1%E7%AE%97/IMG_0749%2820221205-212647%29.PNG)

与无符号数乘法运算电路结构的区别：

1. 没有进位位
2. 增加了一个辅助位，逻辑上位于乘数寄存器的后面

有加减法，均为有符号数加法，右移是**算术右移**

溢出判断：

- 若乘积寄存器位全0或全1，则未溢出
- 否则溢出

### 除法运算

注意以下都是定点数除法，因此要求被除数＜除数，否则无法用定点数表示商

#### 原码除法：恢复余数法

符号位单独处理，无视小数点（即数值位取绝对值进行运算）

初始状态：被除数存储在ACC中，除数存储在通用寄存器中，商在MQ寄存器中，初始化全0

1. 设置MQ寄存器的最低位，默认先商1
2. 将ACC中的数与除数相减，若符号位为0，则说明商正确，继续下一步；否则，改为商0，同时将ACC中的数与除数相加，恢复回原先的ACC值
3. 若商未满n位，则将ACC与MQ视为一个整体（ACC在高位，MQ在低位）共同逻辑左移（因此左移n次，上商n+1次）
4. 重复1-3步，直到求出n位商（设机器字长为n+1位）

余数：最后存储在ACC中，符号位应为0。注意ACC中不是真实余数，**若ACC值为00111，则真实余数为0.0111×2^{-n}**

#### 原码除法：加减交替法/不恢复余数法

实际是恢复余数法的优化。当恢复余数法商1出现负的余数时，在改为商0的同时可以不恢复余数而直接将余数左移并加除数

初始状态：被除数存储在ACC中，除数存储在通用寄存器中，商在MQ寄存器中，初始化全0

1. 设置MQ寄存器的最低位，默认先商1
2. 将ACC中的数与除数相减，若符号位为0，则说明商正确，继续下一步；否则，改为商0，同时将ACC与MQ视为一个整体共同逻辑左移，其中ACC部分与除数相加
3. 若商未满n位，则将ACC与MQ视为一个整体（ACC在高位，MQ在低位）共同逻辑左移（因此左移n次，上商n+1次）
4. 重复1-3步，直到求出n位商（设机器字长为n+1位）

余数：最后存储在ACC中，符号位应与商相同。若余数为负，还需要额外 对余数再加一次除数来得到正确余数。注意这也不是真实余数，**若ACC值为00111，则真实余数为0.0111×2^{-n}**

加/减n+1次，左移n次，最终可能会多出一次加

#### 补码除法：加减交替法/不恢复余数法

- 符号位参与运算
- 被除数/余数、除数采用双符号位表示
- 步骤：
- 被除数与除数同号，则被除数-除数；异号则被除数+除数
- 余数和除数同号，商1，余数左移一位然后-除数
- 余数和除数异号，商0，余数左移一位然后+除数
- 当余数左移的次数等于补码数值位的位数后结束
- 商的末位**恒置为1**，即使余数是负的也不需要再处理

![521FA659F1BC8A6772BE8B2419126155](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x02%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AE%A1%E7%AE%97/521FA659F1BC8A6772BE8B2419126155.png)

![image-20221205212217767](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x02%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AE%A1%E7%AE%97/image-20221205212217767.png)

#### 除法电路的基本结构

![IMG_0748(20221205-212635)](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x02%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AE%A1%E7%AE%97/IMG_0748%2820221205-212635%29.PNG)

### 乘法除法电路的基本结构总结

必须具备的部件：

- ALU：用于实现加、减法
- 具有移位功能的寄存器，乘法运算要求右移，除法运算要求左移
- 控制逻辑：发出加/减控制信号、左移/右移控制信号、写使能信号
- 计数器：用于记录还剩几轮处理

## 2.3 浮点数的表示

### 浮点数的表示

对于固定的8位二进制数据，若采用定点表示，则数据可表示的范围始终是有限且比较小的；浮点数则解决了这个问题。

回忆科学计数法，它由三部分组成：

![image-20220711180251276](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x02%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AE%A1%E7%AE%97/image-20220711180251276.png)

即尾数（绿色）、阶数（青色）和底数（黑色）

#### 浮点数表示法

浮点数也是用同样的方法表示，阶数部分称为阶码，作为浮点数据的前半段；尾数部分就是尾数，作为浮点数据的后半段；底数默认为2，省略。

- 阶码

阶符+阶码的数值部分。是常用补码或移码表示的定点整数。

反映了数据中的小数点要往前/往后浮动多少位

- 尾数（未规格化）

数符+尾数的数值部分。是常用原码或补码表示的定点小数。

注意是定点小数，即整数部分总为0，这一点与十进制的科学计数法不同。

尾数的数值部分的位数n反映浮点数的精度。

#### 浮点数的表示范围

浮点数表示范围关于原点对称。

正上溢：运算结果大于最大整数

负上溢：运算结果小于最小负数

正上溢和负上溢统称为上溢。

正下溢：运算结果在0和最小正数之间

负下溢：运算结果在0和最大负数之间

正下溢和负下溢统称为下溢。

发生下溢时，浮点数值趋近于0，计算机直接当作机器零处理

### 浮点数尾数的规格化

#### 概念

规格化是对尾数存储方式的一种优化，使浮点数能表示尽可能高的精度。

- 左规：尾数算术左移，从而舍弃尾数部分高位连续的0（注意，如果是补码表示的尾数则是连续的1），同时阶数也相应调整。如$2^2\times(+0.01001)$对尾数规格化后得到$2^1\times(+0.10010)$。
- 右规：尾数算术右移，处理浮点数运算结果尾数出现溢出时的情况。

![image-20220711182930743](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x02%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AE%A1%E7%AE%97/image-20220711182930743.png)

#### 细节

1. 对于原码表示的尾数（基数为2），①0.011（0.25+0.125=0.375），规格化后为0.110（这里省略阶码部分的调整）；②1.011（-0.25-0.125=-0.375），规格化后为1.11

形式上的规律就是，**原码表示的小数规格化后，其小数点后第一位一定为1，而整数部分可以为1也可以为0，是符号位**（注意这一点与IEEE754不同，IEEE754格式要求小数表示为$(-1)^S\times1.M\times2^{E-bias}$的形式，即整数部分一定为1，且是一个有效位而不是数值位，并且默认不存储，只存储$M$）

1. 对于补码表示的尾数（基数为2），如1.101（-1+0.5+0.125=-0.375），规格化后为1.010（这里省略阶码部分的调整）

形式上的规律就是，**补码表示的小数规格化后，小数点前后两位一定不相同。**

1. 如果基数改变，如基数为4，则**原码表示的小数规格化后，小数点后两位一定不全为0**
2. 总结：原码表示的规格化小数中的尾数M（即小数点后面的部分，小数点后位的权值为$R^{-1}$、$R^{-2}$...以此类推）的绝对值满足 $1/R≤|M|≤1$，其中$R$为基数。

如，当基数为2时，原码小数1.101中的尾数101的绝对值为$2^{-1}+2^{-3}=0.375＜1/2$，因此1.101不是规格化小数；而原码小数0.11中的尾数11的绝对值为$2^{-1}+2^{-2}=0.75$，$1/2≤0.75≤1$，因此0.11是规格化小数。

### IEEE754

移码，形式上看是直接将补码的符号位取反，从数值上看则是补码（真值）加上一个**固定的偏置值**得到。

如8位移码，就是将8位补码加上128D（$2^{8-1}$）的偏置值得到。

IEEE754对浮点数阶码部分的规定为，对于8位阶码，为补码（真值）加上偏置值（$2^{8-1}-1$）所得。这样规定使得阶码最小值和阶码次小值都对应特殊的二进制数：全1和全0.

![image-20220713155927866](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x02%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AE%A1%E7%AE%97/image-20220713155927866.png)

#### 对数符的规定

数符位于浮点数的最高位。0/1表示数的正负。

#### 对阶码的规定

- 用移码表示，但使用的偏置值为$2^{n-1}-1$而非$2^{n-1}$，其中$n$为阶码部分的位数。
- 采用上述偏置值使得阶码部分可表示的最小值和次小值分别为全0和全1，这两个数用作特殊用途（见下文”表示范围“一节），而不用于表示浮点数的阶数。
- 因此，对于8位阶码，能表示的阶数范围为$-126 到 +127$

#### 对尾数的规定

- 用原码表示
- 完整的小数是$1.M$，但1省略不存储，只存储M。

#### 浮点数的真值计算

| 类型        | 数符S | 阶码E | 尾数数值M | 总位数 | 偏置值 |
| :---------- | :---- | :---- | :-------- | :----- | :----- |
| float       | 1     | 8     | 23        | 32     | 127    |
| double      | 1     | 11    | 52        | 64     | 1023   |
| long double | 1     | 15    | 64        | 80     | 16383  |

- float浮点数的真值

$(-1)^S\times1.M\times2^{E-127}$

- double浮点数的真值

$(-1)^S\times1.M\times2^{E-1023}$

#### 表示范围

- float浮点数的最小绝对值

尾数全为0，阶码真值最小-126，整体真值$1.0B\times2^{-126}$

- float浮点数的最大绝对值

尾数全为1，阶码真值最大127，整体真值$1.1111..11B\times2^{127}$

- 若要表示的数的绝对值比最小的绝对值还要小（如$0.001B\times2^{-126}$），令阶码全为0，要表示的数的小数部分直接作为尾数（此时整数部分一定为0，因为再规格化的话阶码无法表示）。

| 阶码 | 尾数    | 含义                                                |
| :--- | :------ | :-------------------------------------------------- |
| 全0  | 不全为0 | 非规格化小数 （比规格化小数的最小绝对值还要小的数） |
| 全0  | 全0     | ±0                                                  |
| 全1  | 全0     | ±$\infin $                                          |
| 全1  | 不全为0 | NaN                                                 |

## 2.4 浮点数的运算

#### 浮点数的加减运算

1. 对阶：小阶向大阶看齐。尾数每右移一位，阶数+1，直到阶码相等
2. 尾数求和：将对阶后的尾数按定点数加减运算规则运算
3. 规格化
4. 左规：造成下溢，直接当作0处理，不算真正的溢出
5. 右规：造成上溢
6. 舍入
7. 恒置1：多出的直接砍掉，余下的尾数的最后一位恒置为1
8. 规则2：若砍掉的最高数值位为1，则向高位进1
9. 规则3：四舍五入
10. 考试：超出的位数直接丢掉，不舍入
11. 溢出判断
12. 阶码的溢出才是真正的溢出
13. 尾数的溢出可以进行规格化和舍入处理

![81B052432B52CAD91F5638861339CDCC](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x02%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AE%A1%E7%AE%97/81B052432B52CAD91F5638861339CDCC.png)

#### 强制类型转换

- 无损转换

- char→int→long→double

- float→double

- 有损转换

- int→float：可能损失精度（int32位，float的尾数24位）但不会溢出

  > 注：如，这个int类型的数是01FF FFFF（25个1，即2^25-1=33554431），转为float类型后值为3.35544×10^7，即33554400，最末尾的31被抹零了，丢失了精度

- float→int：可能溢出也可能损失精度

# 第三章 存储系统

## 3.1 存储系统基本概念

### 存储器的层次结构

- 高速缓存（Cache）：容量很小、速度可以CPU速度匹配、价格高
- 主存储器（主存）：容量较小、存取速度较快、每位价格较高
- 辅助存储器（辅存、外存）：容量大、读取速度较慢、单位成本低

### 存储器的分类

- 存储介质
- 半导体：如主存、Cache
- 磁性材料：磁盘、磁带
- 光：光盘
- 存取方式
- 随机存取存储器（RAM）：读写任何一个存储单元所需时间都相同，与存储单元所在的物理位置无关。
- 顺序存取存储器（SAM）
- 直接存取存储器（DAM）：如磁盘。既有随机存取特性，又有顺序存取特性。
- 相联存储器（CAM）：可以按照内容检索到存储位置进行读写，如快表
- 信息的可更改性
- 读写存储器：既能读也能写
- 只读存储器（ROM）：只能读、不能写，如CD-ROM，蓝光光碟
- 信息的可保存性
- 易失性存储器（主存、Cache）：断电后，存储信息消失
- 非易失性存储器（磁盘、光盘）
- 破坏性读出：信息读出后，原存储信息被破坏，如DRAM，读出数据后要进行重写
- 非破坏性读出，如SRAM、磁盘、光盘

### 存储器的性能指标

- 存储容量：存储字数（即存储单元的数量）×字长（如1M×8位）
- 单位成本：每位价格=总成本/总容量
- 存储速度：数据传输率=数据的宽度（存储字长）/存储周期

![image-20220713182535539](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x03%20%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image-20220713182535539.png)

- 存取时间：从启动一次存储器操作到完成该操作所经历的时间，分为读出时间和写入时间
- 存取周期/读写周期/访问周期：存取时间+恢复时间。存储器进行一次完成的读写操作所需的全部时间
- 主存带宽/数据传输率：表示每秒从主存进出信息的最大数量，单位为字/秒、字节/秒或位/秒

## 3.2 主存储器的基本组成

### 半导体元件&存储芯片的原理

- 存储元：电容（存储比特）+MOS管
- 根据地址读取/写入数据：

![image-20220713190040332](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x03%20%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image-20220713190040332.png)

- $2^n$个存储单元 $\rightarrow $ $n$位地址 $\rightarrow $ $n$条地址线
- $n$位存储字长 → 一次可读出$n$比特数据 → $n$条数据线

### 如何实现不同的寻址方式

- 如一个存储单元字长为一字节，且按字节寻址，则$2^n$个存储单元对应$n$位地址
- 按字寻址，假设一字=四字节，将字节地址左移两位即得即字地址（字开头第一个字节的地址）

## 3.3 DRAM和SRAM

### 存储元件不同导致的特性差异

- DRAM芯片：使用**栅极电容**存储信息

只有一根数据线，直接根据数据线上的电平判断输出的是0还是1

读出一次后电容放电信息被破坏（破坏性读出），所以需要重写数据，也称为“再生”

读写速度更慢

单个存储元制造成本低，集成度高，因此单位成本低

常用作主存

- SRAM芯片：使用**双稳态触发器**存储信息

两根数据线，分别是BL和BLX，根据哪条线输出低电平来判断输出的是0还是1

读出数据后，触发器状态保持稳定，无需重写

读写速度更快

单个存储元制造成本高，集成度低，因此单位成本高

常用作Cache（更接近CPU）

- DRAM和SRAM都是易失性存储器，信息在断电后丢失

### DRAM的刷新

问题：DRAM中的电容即使不断电，经过2ms时间电容中的电荷就会流失，造成数据丢失，因此需要不断重写数据。

1. 多久需要刷新一次？刷新周期：2ms
2. 每次刷新多少存储单元？以行为单位，每次刷新一行存储单元

#### DRAM中的存储单元结构

在存储单元数量较多时（如百万级），如果只采用单个译码器进行选址，那么译码器的选通线也要有百万条，这在工程上实现难度很大。

为了避免这种情况，DRAM中存储单元排成矩形，译码器分为行地址译码器和列地址译码器两个，分别输出行地址选通信号和列地址选通信号，从而选中存储单元。

这样做可以减少选通线的数量，简化电路

#### DRAM刷新

- 如何刷新：硬件支持，每次读出一行信息后再重新写入，占用1个读/写周期
- 在什么时候刷新：

假设DRAM内部结构为128×128，读/写周期为0.5μs

**分散刷新**：每次读写完都刷新1行，则存取周期=2个读/写周期，前一个读/写周期用于正常读写，后一个读/写周期用于刷新某行。一方面，并非读写哪行就刷新哪行，而是只要发生了读写就刷新一行；另一方面，可以认为读写操作是一直都有的，不会出现没有读写导致没有刷新的情况。这种方式下，在电容保持时间2ms内能把全部128行刷新若干遍。

**集中刷新**：2ms内集中安排一个时间全部刷新。不影响正常读写，因此存取周期=1个读/写周期；但在集中刷新的时间段内无法访问存储器，这段时间称为访存死区。

**异步刷新**：2ms内每行只刷新1次即可。其实是将集中刷新的死时间平均分布在了2ms的时间段中。由于有128行，那么2ms内需要产生128次刷新，即每隔2ms/128=15.6μs一次，每次刷新需要1个读写周期，即每15.6μs中都存在0.5μs的死时间。

### DRAM的地址线复用技术

由于DRAM中存储单元数量大，即使分成两个译码器进行选址，单个译码器所需要的地址线仍然较多。为了进一步减少地址线，地址分两次送入，一次先送入行地址，另一次再送入列地址。

增设行地址缓冲器和列地址缓冲器，两次送入先送到缓冲器上，再由缓冲器送到译码器。

## 3.4 ROM

### ROM的分类

- MROM（掩模式只读存储器）：厂家在生产过程中直接写入信息，任何人不可重写
- PROM（可编程只读存储器）：用户可用专门的写入器写入信息，写一次后不可更改
- FPROM（可擦除可编程只读存储器）：允许用户写入信息，并用某种方式擦除数据，多次重写
- UVEPROM（紫外线擦除）：紫外线照射，擦除所有信息
- EEPROM（电擦除）：电擦除，擦除特定的字
- Flash Memory（闪存）：断电后也可保存信息，并可进行多次快速擦除重写（如U盘、SD卡）；写比读慢。
- SSD（固态硬盘）：多次快速擦除重写。和闪存的核心区别在于控制单元不一样。

### 计算机内的重要ROM

问题：主存RAM断电后数据全部丢失，而操作系统等又都存储在辅存里，那么刚开机的时候CPU从哪里得到指令来启动操作系统？

- 主板上有BIOS芯片，是ROM，存储了自举装入程序，负责引导装入操作系统。
- 主存=RAM+ROM，二者常统一编址

## 3.5 双端口RAM和多模块存储器

### 双端口RAM

问题：多核CPU同时访问同一个主存储器，如何实现？

解决：

- 两组完全独立的数据线、地址线、控制线，分别接到CPU1、CPU2
- CPU、RAM中要有更复杂的控制电路

问题：两个端口的操作有以下4种情况：

1. 同时对不同的地址单元存取数据✓
2. 同时对同一地址单元读出数据✓
3. 同时对同一地址单元写入数据（×写入错误）
4. 同时对同一地址单元，一个写入数据，一个读出数据（×读出错误）

解决：

忙信号，当有一个端口正在进行操作时置忙信号

### 多模块存储器

一个存储器中可能有多个内存条（存储体），需要选择

- 高位交叉编址

- 体号位于地址高位

- 相邻的地址对应的存储单元基本上位于同一个存储体上

- 这会导致，按地址连续访问数据时，操作都针对同一个存储体，而一次操作消耗一个存储周期。

  假设存储体的存取周期为T，存取时间为r，恢复时间为3r，1T=4r，意味着每次操作都要等待较长的恢复时间。

![image-20220714124715661](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x03%20%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image-20220714124715661.png)

- 采用高位交叉编址时，连续取n个存储字的总耗时为nT.

- 低位交叉编址

- 体号位于地址低位

- 相邻的地址对应的存储单元位于不同的存储体上

- 按地址连续访问数据时，每次操作都在与上次操作不同的存储体上，一次操作只需要1r的存取时间，而不必等待3r的恢复时间。如果存储体恰好有4个，则对第4个存储体操作后第1个存储体恰好恢复完毕，存取操作之间可以无缝衔接。

- 采用低位交叉编址时，连续取n个存储字的总耗时为nr+3r=T+(n-1)r（3r是最后一次存取操作后的恢复时间）

  ![image-20220714125519568](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x03%20%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image-20220714125519568.png)

- 应该有多少个存储体？

存取周期为T，存取时间为r，流水线不间断，应保证模块数m≥T/r

m=T/r是最好的，m＞T/r会出现流水线中的气泡

\## 3.6 主存与CPU的连接

\### 单块存储芯片与CPU的连接

\### 多块存储芯片与CPU的连接

\#### 位扩展法

解决的问题：单个存储芯片的字长（如8位）小于CPU能接收的最大字长（64位），没有充分利用CPU和主存间的数据传输能力

方法：

- eg：利用8片8K×1位（$8\times2^{10}\times 1\ bit$）的存储芯片，组成1个8K×8位的存储器，容量为$8\times2^{10}\times8=8KByte$

![image-20220714114207638](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x03%20%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image-20220714114207638.png)

\#### 字扩展法

- 线选：

  单独拿出某条地址线来对应某个芯片的选择；一条地址线只对一个芯片输出使能信号

  弊端：当多条片选地址线同时输出使能信号时，多个芯片同时被使能，造成数据输出冲突

- 片选

  增加一个译码器芯片，如2-4译码器，使得2条地址线信号产生4个不同组合信号对4个不同芯片使能（输出信号0001、0010、0100、1000）

  在实际中这2条地址线应该是相邻的，使得编址是连续的

  考试中可能会出现题目所给的片选地址线不相邻的情况，这是无法实际应用的

\#### 字位扩展法

例如，有8个16K×4位的芯片，两两一组构成位扩展，则一组芯片为16K×8位，组内2个芯片共用使能信号，共4组。CPU使用2条地址线，通过2-4译码器输出4组使能信号，分别对4组芯片使能。从而8个芯片整体组成4×16K×8位的存储器，总容量为64KByte。

地址线总数计算：

- 位扩展不改变存储单元数量，一组位扩展的芯片寻址需要14条地址线（$16K=2^4×2^{10}=2^{14}$）
- 经过2-4译码器对4组芯片产生使能信号，需要2条地址线确定是4组芯片中的哪一组芯片
- 存储器总地址线数量/地址位长为16

## 3.7 Cache的基本概念和原理

问题：双端口RAM、多模块存储器虽然已经经过了优化，提高了存储器的工作速度，但和CPU的速度差距依然很大。

解决：根据程序的“局部性原理”，采用更高速的、容量更小（因为成本更高）的存储单元来作为CPU与存储器之间的中转可以缓解主存与CPU之间的速度矛盾，也就是Cache。Cache的读写速度是主存的60倍。

### Cache的工作原理

- 集成在CPU内部
- 使用SRAM（双稳态触发器、无需重写）实现，速度快，成本高
- 将当前正在访问的主存地址及邻近地址的数据全部放入Cache中

### 性能分析

设$t_c$为访问一次Cache所需时间，$t_m$为访问一次主存所需时间

- 命中率$H$：CPU欲访问的信息已在Cache中的比率
- 缺失率$M$：$M=1-H$
- Cache-主存系统的平均访问时间 $t$

情况1：$t=Ht_c+(1-H)(t_c+t_m)$

- 当访问命中时，CPU直接从Cache取出数据，耗时$t_c$
- 当访问未命中时，浪费了访问Cache的时间$t_c$，还要继续耗费$t_m $时间从主存中取数据，总访问时间为$t_c+t_m$

情况2：$t=Ht_c+(1-H)t_m$

- 同时访问Cache和主存，若Cache命中则立即停止访问主存

### 哪些数据存入Cache

局部性原理

- 时间局部性：现在访问的地址，不久之后很可能被再次访问
- 空间局部性：现在访问的地址，其邻近的地址很可能即将被访问

如何决定哪些数据要被放入Cache中：

- 将CPU目前访问的地址“周围”的部分数据放到Cache中。
- 将主存和Cache的存储空间分块。如1KB一块，主存与Cache之间以块为单位进行数据交换。
- CPU当前访问地址所属的块被复制一份存入Cache。

主存/Cache的块：

- 主存的块又称**页/页框/页面**
- Cache的块又称**行**

### Cache和主存的映射方式

> 问题：如何区分Cache与主存的数据块对应关系？

- 将Cache中的块配一个有效位和一个标记
- 标记说明这个Cache块中的数据来自主存中哪个块
- 有效位标明这个Cache块中的数据是否还有效（是否可以替换）

#### 全相联映射

- 主存中任意一个块可以放入Cache中任意一行。
- 判断命中：若当前需要访问的主存地址为A，用A的前22位（块号）与Cache中的标记逐一匹配，若匹配成功且有效位为1则Cache命中。
- 优点：比较灵活，Cache行冲突概率低，空间利用率高、命中率高
- 缺点：标记比较速度慢，通常用昂贵的按内容寻址的相联存储器进行地址映射

> 假设某计算机中的主存地址空间大小为256MB，按字节编址，数据Cache中有8个Cache行，行长为64B。说明全相联映射方案。

由于主存和Cache需要划分等大的块，主存需要按每64B一块进行分块。

按字节编址，则地址共有$256\times2^{20}=2^{28}$个，则地址位长为28位。

为块内64B数据编址需要占用其中6位，其余22位作为主存块号。

相应的，Cache中的标记也是22位长。

#### 直接映射

- 主存中的一个块只能放在Cache中的固定位置
- 位置计算方式：主存块号%Cache总块数
- 优点：可以根据映射方式的特点，对标记的位长进行优化。假设Cache总块数为$2^3$，则主存块号的末尾3位就是它所对应的Cache行号。那么标记只需要存储主存块号的前19位。

判断命中时，先根据当前访问的地址块号的后3位找到它固定存放的Cache块，再用前19位与该块标记进行匹配即可。

- 缺点：只能放在固定位置，若恰好该Cache行被占用了，即使其他Cache行还空着也不能利用。
- 若在装入新行时发生冲突（对应Cache行已有数据），则无条件替换掉旧行，无需替换算法

#### 组相联映射

- 主存中的一个块放在Cache中的特定分组中的任意一行。
- 所属分组=主存块号%分块数
- 与直接映射类似，若Cache总组数为$2^2$，则主存块号的末2位就是它对应的Cache组号。此时标记位长只需要20位。
- 判断命中时，先根据当前访问的地址块号的后2位找到对应的Cache组，再用前20位与组内Cache块的标记逐个匹配。

### Cache容量计算

每个Cache行除了存储数据以外，还需存储标记项，标记项包括：有效位、标记位、一致性维护位、替换算法控制位。

有效位：1位

标记位：与主存块号长度及映射方式相关。如主存块号长度22位，Cache行数为8，则

- 直接映射方式下，标记位长度19位；
- 全相联映射方式下，标记位长度22位；
- 二路组相联映射方式下，标记位长度20位

![image-20221020150842003](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x03%20%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image-20221020150842003.png)

解：（1）行长64B是指不包括标记项的净存储大小。计算可得地址位数有28位，而块内地址有64个，占6位地址，则块号共有22位。采用直接映射方式，8行需要3bit表示，故标记位只需22-3=19bit。有效位需要1bit，不考虑其他，则每个Cache行有标记项共20bit+净存储大小512bit=532bit，8行总共4256bit。所以Cache总容量为4256bit

（2）一块有64个地址，地址3200对应3200/64=50，块号为50；50%8=2，故对应Cache行号为2，即010

### Cache替换算法

> 问题：Cache很小，主存很大。Cache满了怎么办？

#### 随机算法（RAND）

若Cache已满，则随机选择一块替换。

实现简单，但完全没考虑局部性原理，命中率低，实际效果很不稳定

#### 先进先出算法（FIFO）

若Cache已满，则替换最先被调入Cache的块

实现简单，但依然没考虑局部性原理，最先被调入Cache的块也可能是被频繁访问的

抖动现象：频繁的换入换出现象（刚被替换的块很快又被调入）

#### 近期最少使用算法（LRU）

为每一个Cache块设置一个**计数器**，用于记录该Cache块有多久未被访问。当Cache满时替换计数器最大的块。

具体方法：

- Cache块命中时，该块计数器清零，且比其先前计数还要低的块+1，其它不变。
- 未命中且还有空闲块时，新装入的块计数器置0，其他非空闲块+1
- 未命中且无空闲块时，计数器最大的Cache块被淘汰，新装入的块计数器置0，其他全部+1

上述方法造成的现象是，若Cache块总数为$2^n$，则计数器的数字一定只在$0到2^n-1$之间，使计数器可以用$n$位二进制数存储。且Cache装满后所有计数器的值一定不重复。

本算法基于“局部性原理”，实际运行效果优秀，Cache命中率高。

但若频繁访问的主存块数量＞Cache块数量，依然会发生抖动现象。

#### 最不经常使用算法（LFU）

为每一个Cache块设置一个**计数器**，记录每个Cache块被访问过几次。当Cache块满后替换计数器最小的块。若计数器最小的块有多个，可按行号递增、或FIFO策略进行选择。

计数器数字可能会很大。

曾经最经常访问的主存块在未来不一定会用到，并没有很好地遵循局部性原理，实际运行效果不如LRU

### Cache写策略

> 问题：CPU修改了Cache里的数据副本，如何确保主存中数据母本的一致性？

### 写命中

CPU对某个主存地址对应的数据进行写操作，且该数据已经被调入Cache块。

#### 写回法

CPU对Cache块写命中时，只修改Cache中的内容，而不立即写入主存。当此块被换出时才写回主存。

为了节省时间，需要区分哪些块需要被写回而哪些块不需要。因此对每个Cache块增加一个**脏位**，用于标记Cache块内数据是否被修改过

减少访存次数，但存在数据不一致的隐患

#### 全写法

CPU对Cache块写命中时，同时修改Cache和主存中的内容。

访存次数增加，速度变慢，但更能保证数据一致性。

一般使用写缓冲（SRAM实现的FIFO队列），而不是由CPU分别修改Cache和主存的数据。具体是，CPU写命中时，同时修改Cache内容和写缓冲的内容（修改写缓冲比修改主存更快），CPU执行其他操作时，写缓冲再由硬件电路控制修改主存内容。

使用写缓冲，CPU写的速度很快，若写操作不频繁则效果很好；但若写操作很频繁，则会因为写缓冲饱和而发生阻塞，换句话说，此时写缓冲成为了读写速度的瓶颈。

### 写不命中

CPU对某个主存地址对应的数据进行写操作，但该数据不在Cache中。

#### 写分配法

将主存中的块调入Cache，CPU再在Cache中修改。通常搭配写回法使用。

#### 非写分配法

CPU直接向主存写数据，不调入Cache。搭配全写法使用。

### 多级Cache

![image-20220714202437106](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x03%20%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image-20220714202437106.png)

离CPU越近的速度越快，容量越小

离CPU越远的速度越慢，容量越大

## 3.8 页式存储器

> 一个程序所需的内存空间可能很大（如1GB），但实际到CPU执行时可能只需要其中的一小部分信息（如1KB），若直接将程序全部装载到内存中会导致内存利用率不高。如何解决？

主存和Cache被划分为若干个等大的块，假设块大小为1KB（之前提到，主存块又被称为页/页面）。现有某程序大小为4KB，则程序会被分为4个**页**，每个页面的大小和主存块的大小相同。这四个页在主存中**分散存储**。

### 逻辑地址与物理地址

程序编写/执行时采用的机器指令中的地址是逻辑地址。

------

> 逻辑地址如何对应程序分页中的数据？

整个程序共$4KB=2^{12}B$，地址位长12，范围0x000~0xFFF

由于一页大小为1KB，按字节编码则需要10位地址，为页内地址；其余2位则为逻辑页号。

知道了数据的逻辑地址，则可以通过某种映射方式来找到对应的物理地址，即主存地址。这一步骤由操作系统完成。

------

> 逻辑地址具体如何映射到物理地址？

### 页表

页表保存了逻辑页号与主存块号之间的一一对应信息。形如下表：

| 逻辑页号 | 主存块号 |
| :------- | :------- |
| #0       | 2        |
| #1       | 4094     |
| ...      | ...      |

知道了逻辑页号，就可以通过页表找到对应的主存块号。

而页内地址就是块内地址（因为逻辑页和主存块大小是一样的），与主存块号拼接即得物理地址。

> 如何知道页表本身数据所在的物理地址？

有专门的**页表基址寄存器**负责保存页表在主存中的存放位置。

------

> 根据局部性原理，同样的逻辑页号可能会多次访问，每次都要去页表查找吗？

查询页表的速度是很慢的，所需时间相当于一次访存。

在实际中，会将近期访问的页表项放入更高速的存储器（使用SRAM），加快地址变换的速度，这个类似Cache的存储器就是**快表**。相对的，普通的页表就是慢表。

### 快表（TLB）

存储页表项的副本（也就是常用索引的副本）

使用SRAM实现，查询速度很快。

是一种相联存储器，即可以按数据内容访问（而不是按地址）。

### 访存流程总结

![按逻辑地址访问存储器的流程](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x03%20%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/%E6%8C%89%E9%80%BB%E8%BE%91%E5%9C%B0%E5%9D%80%E8%AE%BF%E9%97%AE%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E6%B5%81%E7%A8%8B.jpg)

## 3.9 虚拟存储器

### 虚拟存储系统

主存——辅存之间的数据调度，解决主存容量不够的问题。

通过运行时才将所需的部分程序数据从辅存调入主存的方式，使得总数据量远大于主存容量的多个程序可以同时在计算机上运行，给用户一种主存非常大的错觉，因此是“虚拟”存储系统。

### 页式虚拟存储器

将原本位于辅存中的程序数据按页划分，每页大小相同。

当程序运行时，按页将所需数据从辅存调入到主存中，分散存储。

#### 页表所需要承担的功能

除了保存前文所述的存储逻辑页号与主存块号的映射关系以外，页表还存储了辅存-主存数据调度所需信息，包括类似于Cache中的有效位、脏位等。

| 逻辑页号 | 主存块号 | 外存块号 | 有效位 | 访问位 | 脏位 |
| :------- | :------- | :------- | :----- | :----- | :--- |
| #0       | 2        | a        | 1      | 13     | 0    |
| ...      | ...      | ...      | ...    | ...    | ...  |

首先，当逻辑页号对应的数据实际上还没有被调入到主存中时，逻辑页号-主存块号这一映射关系应该是无效的，反之映射关系有效。为了标记这一点，需要用到**有效位**。

其次，当逻辑页号对应的数据还在辅存中而未调入主存时，需要先到辅存中找到对应的数据。去哪里找？页表也保存了逻辑页号-**外存块号**这一映射关系，可以根据逻辑页号，通过页表去辅存中找到对应数据。

再次，主存很小而辅存很大，若主存已满，同样需要进行替换。主存的替换为**页面替换**。同样的，需要有相应的页面替换算法，**访问位**用于记录算法实现所需要的信息。

最后，CPU对主存数据有修改时，如何保证主存-辅存的数据一致性？**脏位**用于标记主存块中数据是否被修改。脏位结合写回算法实现主存-辅存的数据一致性。

### 段式虚拟存储器

将辅存中的程序数据按功能模块进行划分，每个模块为一段。如源代码段、库函数段、变量段等。

分段的方式会使得各段并不等长。使用**段表**来记录相关信息。

![image-20220715012927315](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x03%20%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image-20220715012927315.png)

### 段页式虚拟存储器

将程序数据按逻辑结构先分段，段内再划分为固定大小的页。

主存空间也划分为等大的页。

主存-辅存之间的数据调入/调出仍以页为单位。

每个程序对应一个段表，每段对应一个页表。

虚拟地址=段号+段内页号+页内地址。

## 3.10 外存储器

### 磁盘存储器

#### 磁盘存储器的优缺点

- 磁表面存储器的优点：
- 存储容量大、位价格低
- 记录介质可以重复使用
- 记录信息可以长期保存而不丢失，甚至可以脱机存档
- 非破坏性读出，读出时不需要再生
- 磁表面存储器的缺点：
- 存取速度慢
- 机械结构复杂
- 对工作环境要求较高

#### 磁盘设备的组成

- 硬盘存储器的组成：磁盘驱动器+磁盘控制器+盘片
- 磁盘驱动器：磁头组件+盘片组件。温彻斯特盘是可移动磁头固定盘片的硬盘存储器
- 磁盘控制器：硬盘存储器和主机的接口
- 存储区域
- 一块硬盘含有若干个记录面，每个记录面划分为若干条磁道，每条磁道又划分为若干个扇区，扇区（块）是磁盘读写的最小单位。
- 磁头数：即记录面数
- 柱面数：每一面盘片上有多少条磁道
- 扇区数：每一条磁道上有多少个扇区

#### 性能指标

- 容量：存储的字节总数
- 记录密度：盘片上单位面积上的记录的二进制的信息量
- 道密度：沿半径方向单位长度上的磁道数（如一厘米有多少圈）
- 位密度：磁道单位长度上能记录的二进制位数（如一圈能记录多少位）
- 面密度：位密度和道密度的乘积（一厘米的环面能记录多少位）

所有磁道记录的信息量一定是相等的，故每个磁道的位密度都不同，越往外越小。

- 平均存取时间：寻道时间（移动到目标磁道）+旋转延迟时间（移动到目标扇区）+传输时间（传输数据的时间）
- 数据传输率：单位时间内向主机传送数据的**字节数**

#### 磁记录原理

电磁转换

#### 磁盘地址

- 驱动器号+磁道号+盘面号+扇区号

#### 磁盘的工作过程

- 寻址、读盘、写盘，每个操作对应一个控制字
- 读写操作是**串行**的，1bit1bit地读出/写入

#### 磁盘阵列(RAID)

多个独立的物理磁盘组成一个独立的逻辑盘，数据在多个物理盘上分割交叉存储、并行访问，具有更好的存储性能、可靠性和安全性

类比低位交叉编址的多体存储器

- RAID0：无冗余和无校验的磁盘阵列。没有容错能力。
- RAID1：镜像磁盘阵列。两个磁盘同时进行读写、互为备份。容量减少一半
- RAID2：采用纠错的海明码
- RAID3：位交叉奇偶校验
- RAID4：块交叉奇偶校验
- RAID5：无独立校验的奇偶校验磁盘阵列

### 固态硬盘

采用高性能Flash Memory记录数据，由E2PROM发展而来。

实际上是ROM，和U盘没有本质区别，只是容量更大、存取性能更好

一个闪存由若干个块组成，每块由若干个页组成，数据以页为单位读写。只有在一页所属的块全部被擦除后，才能写这一页；如果整个块都被擦除过，则该块内的所有页内可以写。一个块经过约10万次重复写后就会磨损坏，无法使用。

随机写很慢：1. 擦除块很慢，1ms级；2.如果需要写一个已有数据的页P，则必须先把这些数据复制到一个新的块中，才能写P

反复写之后，闪存块会磨损。闪存翻译层通过一个平均磨损逻辑将擦除平均分布在所有的块上，从而最大化每个块的寿命

### 光盘存储器

利用光学原理读/写信息的存储装置。

分类：

CD-ROM（只读）、CD-R（只能写一次）、CD-RW（可读可写）、DVD-ROM（高容量的CD-ROM）

# 第四章 指令系统

## 4.1 指令格式

- 指令/机器指令：指示计算机执行某种操作的命令，是计算机运行的**最小功能单位**
- 指令系统/指令集：一台计算机的所有指令的集合
- x86架构（Intel）、ARM架构（手机）

### 指令格式-按指令地址数分类

**指令通常由操作码+地址码构成**。

#### 零地址指令

不需要操作数，如空操作、停机、关中断等命令

如堆栈计算机，两个操作数隐含放在栈顶和次栈顶，计算结果压回栈顶。

#### 一地址指令

1. 只需要单操作数，如加1、减1、取反、求补等
2. 需要两个操作数，但其中一个操作数在某个寄存器中（就不需要通过地址码来读出数据）

#### 二地址指令

需要两个操作数的算术运算、逻辑运算等，计算结果放回其中一个操作数的地址。

完成一条指令需要访存4次，取指$\rightarrow$读A1$\rightarrow$读A2$\rightarrow$写A1

#### 三地址指令

需要两个操作数的算术运算、逻辑运算等，计算结果放到不同于两个操作数的新地址。

#### 四地址指令

OP+$A_1$地址+$A_2$地址+$A_3$（结果）地址+$A_4$（下一条指令的地址）

执行指令后，将PC的值修改为$A_4$

### 指令格式-按指令长度分类

指令字长：一条指令的总长度（可能会变）

根据指令长度与机器字长的关系，分为半字长指令、单字长指令和双字长指令。

根据指令系统中所有指令的长度是否都相等，分为定长指令字结构和变长指令字结构

### 指令格式-按操作码长度分类

根据指令系统中所有指令的操作码长度是否都相等，分为定长操作码和可变长操作码。

对于定长操作码来说，操作码的位数决定了系统指令的种类数。

### 指令格式-按操作类型分类

1. 数据传送
2. LOAD：把存储器中的数据放到寄存器中
3. STORE：把寄存器中的数据放到存储器中
4. MOV：寄存器之间的数据传送
5. 算术逻辑操作
6. ADD：加
7. SUB：减
8. CMP：比较
9. MUL：乘
10. DIV：除
11. INC：加1
12. DEC：减1
13. 移位操作
14. 算术移位、逻辑移位、循环移位
15. 转移操作
16. JMP：无条件转移
17. BRANCH：条件转移
18. RET：调用和返回
19. TRAP：陷阱和陷阱指令
20. 输入输出操作
21. CPU寄存器与IO端口之间的数据传送

## 4.2 扩展操作码指令格式

扩展操作码指令格式：定长指令字结构+可变长操作码

> 如何扩展？

设指令字长为16位，每个地址码占4位。

考虑三地址码的情况，此时操作码位数为4位，则令0000～1110作为三地址指令的操作码，将1111留作扩展。则三地址指令为15条。

对于二地址码，此时操作码位数为8位，注意到高4位已经被三地址指令的操作码占用了15个，二地址码的高4位只能是1111。同样地，将1111 1111留作扩展，则二地址指令同样为15条。

对于一地址码，此时操作码位数为12位，高8位已经被三地址指令和二地址指令使用了255个，一地址码的操作码高8位只能是1111 1111。则一地址指令同样为15条。

**设计原则**

- 不允许短码是长码的前缀，这就是为什么高位一定要留下至少一个状态以作扩展。
- 各指令的操作码一定不能重复

> 设指令字长固定为16位，试设计一套指令系统满足：
>
> - 有15条三地址指令
> - 有12条二地址指令
> - 有62条一地址指令
> - 有32条零地址指令

高4位0000-1110作为三地址指令操作码，共15条，留1111扩展；

高8位1111 0000 - 1111 1011作为二地址指令操作码，共12条，留1111 1110、1111 1101、1111 1100、1111 1111扩展；

一地址指令对于高8位留下的4种前缀，其中3种均用满，共16*3=48条指令，最后一种使用1111 1111 0000 - 1111 1111 1101, 则共48+14=62条指令，留1111 1111 1110和1111 1111 1111作扩展；

零地址指令对于高12位留下的2种前缀均用满，则共16*2=32条指令。

**规律**：设地址长度为n，若上一层留出了m个状态，则本层可扩展出$m\times2^n$种状态。

## 4.3 指令寻址

### 顺序寻址

> 如何确定下一条指令的地址？PC+1的1是如何确定的？如果主存按字节编址，采用变长指令字结构怎么办？

读入一个字，CPU根据操作码判断这条指令的总字节数n，以此修改PC的值：（PC）+n$\rightarrow$(PC)。这样，就能使PC中的值为下一条指令的首字节地址。

根据操作码，CPU可能还会进行多次访存，每次访存读入一个字。

故，PC+1中的1其实是指1个指令字长。

### 跳跃寻址

**下一条指令的地址的计算方式**由转移指令给出。

给出的地址分为绝对地址和相对地址（相对于当前指令地址的偏移量）

跳跃的结果是当前指令修改PC值，故**下一条指令地址**仍通过PC给出

## 4.4 数据寻址

数据寻址解决的问题是，确定**本条指令**的**地址码指明的真实地址**。

数据寻址方式有多种，如隐含寻址、立即寻址、直接寻址、间接寻址、寄存器寻址、寄存器间接寻址、相对寻址、基址寻址、变址寻址、堆栈寻址。

转移指令中的地址，根据不同的数据寻址方式可以被解读为不同的真实地址。因此地址码又分为两部分，一部分为**寻址特征**，表明数值寻址方式，另一部分为**形式地址A**。

综上，数据寻址的指令格式为：操作码-寻址特征-形式地址

### 隐含寻址

指令字中隐含着操作数的地址（实际上指令字中不包含操作数的地址，而是默认了操作数在某处，如ACC，在执行指令的过程中自然会使用）

隐含寻址方式可以使得理论上的二地址指令缩短为一地址指令。如`ADD 地址1 地址2`，实际中是`ADD 地址1`

优点：有利于缩短指令字长

缺点：需增加存储操作数或隐含地址的硬件

### 立即（数）寻址

形式地址A就是操作数本身，又称为立即数，一般采用补码形式。寻址特征字段用#表示立即寻址。

优点：指令执行阶段不访问主存，指令执行时间最短

缺点：A的位数限制了立即数的范围。

![image-20220716201850494](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x04%20%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F/image-20220716201850494.png)

### 直接寻址

指令字中的形式地址A就是操作数的真实地址EA，即EA=A

优点：简单，指令执行阶段仅访问一次主存，不需专门计算操作数的地址。

缺点：A的位数直接决定了该指令操作数的寻址范围，操作数的地址不易修改

不考虑结果的存储，则在直接寻址中，一条指令的执行需要在取指令、执行指令时各访存1次，共访存2次。

### 间接寻址

指令字中的形式地址A不是操作数的真实地址，而是操作数有效地址所在存储单元的地址，即EA=(A)。即，CPU根据形式地址A在主存中找到真实地址，再根据真实地址在主存中找到操作数。

不考虑结果的存储，则在间接寻址中，一条指令的执行需要在取指令阶段访存1次、执行指令时访存2次，共访存3次。

优点：可扩大寻址范围，即有效地址EA的位数大于形式地址A的位数；便于编制程序，可以方便地完成子程序返回

缺点：指令在执行阶段需要多次访存。

### 寄存器寻址

在指令字中直接给出操作数所在的寄存器编号，即$EA=R_i$，其操作数位于$R_i$寄存器中。

优点：指令在执行阶段不访问主存，只访问寄存器；指令字短且执行速度快

缺点：寄存器价格昂贵，计算机中寄存器个数有限

### 寄存器间接寻址

在指令字中给出一个寄存器编号，该寄存器中存储操作数真实地址，再根据真实地址到主存中读取操作数。

### 偏移寻址

基址寻址、变址寻址、相对寻址都可以归为偏移寻址，指令字中的形式地址A实际上是个偏移值，CPU需要根据偏移值进行相关计算得到真实地址。上述三种寻址方式的区别在于偏移的“起点”不一样。

- 基址寻址：以程序的起始存放地址作为“起点”，EA=(BR)+A
- 变址寻址：程序员自己决定从哪里作为“起点”，EA=(IX)+A
- 相对寻址：以程序计数器PC所指地址作为“起点”，EA=(PC)+A

#### 基址寻址

将CPU中基址寄存器（也就是OS中的重定位寄存器）的内容加上指令字中的形式地址A，形成操作数的有效地址，即EA=(BR)+A

既可以采用专用寄存器BR作为基址寄存器，也可以采用通用寄存器作为基址寄存器。对于后者，需要在指令字中指明要将哪个通用寄存器作为基址寄存器。

优点：便于程序“浮动”（指令的地址是偏移量，可以根据程序的起始地址灵活确定），方便实现多道程序并发运行。可以扩大寻址范围。

注意，基址寻址中的基址寄存器的内容由操作系统管理，程序员不能修改。

#### 变址寻址

将CPU中变址寄存器IX的内容加上指令字中的形式地址A，形成操作数的有效地址，即EA=(IX)+A。但在应用中，指令字中的形式地址A是固定的，IX中的内容才是变量。

例如，实现数组中的n个值累加，如果使用直接寻址方式，则需要n条指令，每条指令的地址码是数组中各元素的地址。这样的寻址方式未能充分利用数组元素地址连续的特性。

使用变址寻址方式，则可以将n条指令精简为可以循环执行的4条指令：ACC加法、IX加法、IX比较、条件跳转。**数组首地址作为固定的形式地址A**放在ACC指令中，CPU执行该指令时，使用变址寻址，让IX中的地址递增并比较，最后执行转移指令，即可循环执行实现数组的遍历及数组中n个值累加。

与基址寻址的区别是，变址寻址中的变址寄存器是面向用户的，变址寄存器的内容可由用户改变（由上述指令执行过程也可以看出）。

#### 基址&变址复合寻址

在前文所述的数组元素累加的例子中，注意到我们需要先给出数组首地址作为变址寻址的基地址。那么数组首地址又该以何种寻址方式给出呢？显然就该用到基址寻址了。

通过基址寻址的方式，数组首地址是由程序起始地址偏移后给出的（实际中程序存储会采用“分段”的方式，即程序段和数据段分开，所以数组首地址相对于程序起始地址的偏移量可以是固定的），保证了程序的“浮动”，并且相对固定地直接写在指令字中。而以数组首地址为基准的一系列变址寻址，使得CPU可以通过反复地执行几条指令来逐个访问数组元素。

上述方式就是基址&变址复合寻址。

#### 相对寻址

把程序计数器PC的内容加上指令字中的形式地址A，形成操作数的真实地址。其中A是相对于PC所指地址（也就是含A的这一条指令的下一条指令的地址）的偏移量，可正可负，补码表示。

在应用中，相对寻址可以实现条件跳转。如一段for循环，包含若干条指令，每次执行到末尾时要求跳转回循环的第一条指令。以直接寻址的方式可以实现跳转（直接将指令地址码写为第一条指令的地址），但当程序代码发生改动后，for循环第一条指令的地址可能也会改变，导致末尾跳转失败。

但我们知道，for循环中的这若干条指令的相对位置是固定的，如跳转指令往前数4个地址就是循环的第一条指令。显然我们可以以跳转指令所在的地址为基准，偏移-5得到第一条指令的地址。然而跳转指令所在的地址也不是绝对固定的，所以最佳方案就是等CPU执行到跳转指令时，再根据当前地址-4就可以计算出第一条指令的地址了。

要注意的是，相对寻址是**以PC中的地址**为基准，而在执行需要进行相对寻址的指令时，PC已经自动+1，指向了下一条指令。因此在上述的例子中，跳转指令的地址码应该写-5而非-4。

优点：操作数地址随PC值变化而变化，与指令所在的地址之间总是相差一个固定值，便于程序浮动（一段代码在程序内部的浮动）；相对寻址广泛应用于转移指令。

### 堆栈寻址

操作数存放在堆栈中，隐含使用堆栈指针（SP）作为操作数地址。

堆栈是一块专门的存储区域，实际可以是专用的寄存器组，也可以是在存储器中一块特定的、按“后进先出”方式管理的存储区。在该存储区中被读/写单元的地址是用一个特定的寄存器给出的，该寄存器称为堆栈指针（SP）。

## 4.5 程序的机器级代码表示

### 常用汇编指令

#### 寄存器

x86处理器中含8个32位通用寄存器

| 寄存器名 | 说明                                                         | 功能         |
| :------- | :----------------------------------------------------------- | :----------- |
| EAX      | 高2字节和低2字节可以独立使用，低2字节为AX，AX的高低两个字节又分别称为AH和AL | 累加器ACC    |
| EBX      | 高2字节和低2字节可以独立使用，低2字节为BX，BX的高低两个字节又分别称为BH和BL | 基址寄存器BR |
| ECX      | 高2字节和低2字节可以独立使用，低2字节为CX，CX的高低两个字节又分别称为CH和CL | 计数寄存器CR |
| EDX      | 高2字节和低2字节可以独立使用，低2字节为DX，DX的高低两个字节又分别称为DH和DL | 数据寄存器DR |
| ESI      |                                                              | 变址寄存器   |
| EDI      |                                                              | 变址寄存器   |
| EBP      |                                                              | 堆栈基指针   |
| ESP      |                                                              | 堆栈顶指针   |

#### 汇编指令格式 AT&T与Intel

![image-20221022145125790](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x04%20%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F/image-20221022145125790.png)

主要需要注意：

1. AT&T中是前源后目的；Intel中是前目的后源
2. AT&T中 8(%edx,%eax,2) 表示操作数为 M[R[edx]+R[eax]*2+8]，即操作数在主存中的地址为R[edx]+R[eax]*2+8
3. AT&T的后缀，b为字节，w为字，l为双字，这里一字都为16位

![image-20221022145546885](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x04%20%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F/image-20221022145546885.png)

#### 常用指令

以下示例为Intel格式。

- mov
- 寄存器和寄存器、寄存器和内存之间的数据复制。注意不能用于内存和内存之间
- `assembly mov eax, ebx # 将ebx的值复制到eax mov byte ptr [var], 5 #将数值5保存到地址为var的1字节内存单元中`
- push/pop
- 操作数入栈/出栈。栈顶指针由寄存器ESP保存，指令中不写。
- 需要注意的是栈是向低地址方向增长的，新元素入栈时栈顶指针是减的
- `assembly push eax #将eax的值入栈 push [var] #将内存地址为var处的4字节数据入栈`
- add/sub
- 将两个操作数相加/相减，结果保存到第一个操作数中
- `assembly sub eax, 10 # eax ← eax-10 sub bx, ax # bx ← ax - bx add byte ptr [var], 10 # [var] ← [var] + 10`
- inc/dec
- `assembly inc dword ptr [var] #内存地址var处的4字节值自增1 dec eax #eax值自减1`
- imul
- 若指令中含两个操作数，则将两个操作数相乘，结果保存在第一个操作数中。且第一个操作数必须为寄存器
- 若指令中含三个操作数，则将第二个和第三个操作数相乘，结果保存在第一个操作数中。且第一个操作数必须为寄存器
- `assembly imul eax, [var] # eax ← eax * [var] imul esi, edi, 25 #esi ← edi * 25`
- idiv
- 带符号数整数除法。指令中只写出除数，被除数保存在edx:eax（64位整数）中。商送到eax，余数送到edx
- `assembly idiv ebx`
- and/or/xor
- 逻辑与/逻辑或/逻辑异或
- 操作结果放在第一个操作数中
- not
- 取反，实际上是将所有位翻转
- `assembly not byte ptr [var] #将内存地址var处的一字节的所有位翻转`
- neg
- 取负值
- shl/shr
- shl 逻辑左移；shr 逻辑右移
- `assembly shl eax, 1 #将eax值左移1位 shr ebx, cl #将ebx值右移n位（n为寄存器cl中的值）`
- jmp
- 跳转到 label 所指示的地址
- `assembly jmp <label>`
- jcondition
- 条件转移指令，根据CPU状态字中的条件状态转移，由一系列指令构成
- `assembly je <label> #等于时跳转 jne <label> #不等时跳转 jz <label> #等于零时跳转 jg <label> #大于时跳转 jge <label> #大于等于时跳转 jl <label> #小于时跳转 jle <label> #小于等于时跳转`
- cmp/test
- cmp指令用于比较两个操作数的值。
- test指令对两个操作数进行**逐位与**运算。
- 根据运算结果改变CPU状态字中的条件码
- `assembly test eax, eax #测试eax是否为零`
- call/ret
- call指令执行时，首先将当前执行指令地址入栈（?），然后无条件转移到由标签指示的指令
- ret弹出栈中保存的指令地址，然后无条件转移到该地址执行

```
call <label>
ret
```

### 过程调用的机器级表示

- 被调用者保存寄存器：
- EBX、ESI、EDI
- 寄存器内容由被调用者负责保存。如过程P调用了过程Q，Q为被调用者。过程P在调用Q之前在EBX中存储了一些数值，而Q在执行过程中又需要用到EBX，则Q需要先把EBX中属于P的数值存放在自己的栈帧中（内存），然后使用EBX。在Q退出时需要把属于P的数值从栈帧中取出放回到寄存器EBX。
- 调用者保存寄存器：
- EAX、ECX、EDX
- 寄存器内容由调用者负责保存。过程P调用了过程Q，而P在调用Q之前在EAX中存储了一些数值，则P需要提前将这些数值存放到自己的栈帧中，再调用Q，因为Q可以随便修改寄存器EAX。

### 选择语句的机器级表示

#### 条件码/标志位

条件码/标志位保存在CPU的一组专门的寄存器中。它们表示了**最近**的算数或逻辑运算操作的属性。

- CF：进（借）位标志。最近的无符号整数加/减运算后进/借位的情况。若有则为1，无则为0。eg. FFE8H+7FE6H = (1)7FCEH 是有进位而无溢出的
- ZF：零标志。最近的操作的运算结果是否为0。若是则为1，否则为0
- SF：符号标志。最近的带符号数运算结果是否为负数。若为负则为1，否则为0
- OF：溢出标志。最近的带符号数运算结果是否溢出。若是则为1，否则为0

### 循环语句的机器级表示

#### do-while循环

```
do
    body_statement
    while(test_expr);
loop:
    body_statement
    t=test_expr;
    if(t)
        goto loop;
```

## 4.6 CISC和RISC

- CISC: Complex Instruction Set Computer
- 设计思路：一条指令完成一个复杂的基本功能
- 代表：x86架构
- RISC: Reduced Instruction Set Computer
- 设计思路：一条指令完成一个基本“动作”；多条指令组合完成一个复杂的基本功能
- 一定采用指令流水线，有较多的通用寄存器
- 代表：ARM架构

![image-20221022165345396](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x04%20%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F/image-20221022165345396.png)

# 第五章 中央处理器

## 5.1 CPU的功能和基本结构

### CPU的功能

- 指令控制：完成取指令、分析指令和执行指令的操作，即程序的顺序控制
- 操作控制：管理并产生指令对应的操作信号，并把操作信号送往相应的部件，从而控制这些部件按指令的要求进行动作
- 时间控制：为每条指令按时间顺序提供应有的控制信号
- 数据加工：对数据进行算术和逻辑运算
- 中断处理：对计算机运行过程中出现的异常情况和特殊请求进行处理

### CPU的基本结构

CPU主要由运算器和控制器构成。

运算器：对数据进行加工

控制器：协调并控制计算机各部件执行程序的指令序列，基本功能包括取指令、分析指令（操作码译码）、执行指令、中断处理

#### 数据通路

- 专用数据通路：每个寄存器都分别向ALU的两个端口连线，端口处通过多路选择器或三态门控制通路的输出。
- CPU内部单总线：将所有寄存器的输入端和输出端都连接到一条公共的通路上。结构简单容易实现，但数据传输存在较多冲突现象，性能较低。

#### 运算器的基本结构

1. 算术逻辑单元：主要功能是进行算术/逻辑运算
2. 通用寄存器组：如AX、BX、CX、DX、SP等，用于存放操作数和各种地址信息。
3. 暂存寄存器：采用单总线结构，需要增加暂存寄存器，用于暂存从主存读来的数据。这样就不用先将主存读来的数据存储到通用寄存器中，避免对通用寄存器的占用和内容破坏。
4. 累加寄存器：也是单总线结构下的一种暂存寄存器，但暂存的是ALU的计算结果，避免同一次计算的输入信号和输出信号在总线上的冲突。
5. 程序状态字（PSW）寄存器：保留由算术逻辑运算指令或测试指令的结果而建立的各种状态信息，如溢出标志、符号标志、零标志、进位标志等。
6. 移位器：对运算结果进行移位运算（乘除法会大量用到）
7. 计数器：控制乘除运算的操作步数

#### 控制器的基本结构

1. 程序计数器：用于指出下一条指令在主存中的存放地址
2. 指令寄存器：用于保存当前正在执行的那条指令
3. 指令译码器：仅对操作码字段进行译码，向控制器提供特定的操作信号
4. 微操作信号发生器：根据IR的内容、PSW的内容及时序信号，产生控制整个计算机系统所需的各种控制信号，其结构有组合逻辑型和存储逻辑型两种
5. 时序系统：用于产生各种时序信号，它们都是由统一时钟（CLOCK）分频得到
6. 地址寄存器（MAR）（原本是主存的结构之一，但现在一般集成在CPU里面）：用于存放所要访问的主存单元的地址
7. 数据寄存器（MDR）（原本是主存的结构之一 ，但现在一般集成在CPU里面）：用于存放向主存写入的信息或从主存中读出的信息

## 5.2 指令的执行过程

### 指令周期、机器周期、时钟周期

指令周期是指CPU从主存中每取出并执行一条指令所需的全部时间。

在一个指令周期中，CPU需要完成若干阶段的工作，其中一个主要阶段是取指令（也包含对指令译码，但译码时间相对来说非常短），另一个主要阶段是执行指令。取指令的耗时称为取指周期，执行指令的耗时称为执行周期。

除了取指令和执行指令这两个阶段外，不同的指令还会有其他阶段。

- 带有中断周期的指令，会在执行周期结束后开始中断周期，用于检查内部是否存在中断指令、保存程序断点；
- 指令为间接寻址，则还需要在取指周期结束后进行间址周期，在这期间访存以取得指令操作数的真实地址。

CPU周期/机器周期：CPU完成一个阶段工作的耗时

- 取指令和执行指令各占一个机器周期。
- **注意CPU周期/机器周期可以是定长的也可以是不定长的。**
- **通常由存取周期确定**

一个CPU周期/机器周期又包含若干时钟周期（也称为节拍/T周期/CPU时钟周期），时钟周期是CPU操作（微操作）的最基本单位，也就是CPU主频的倒数。

每个指令周期内机器周期数可以不等，每个机器周期内的时钟周期也可以不等。

### 指令周期的数据流

CPU内部设置了4个标志触发器 FE、IND、EX 和 INT，分别对应取指、间址、执行和中断周期，“1”表示有效。

#### 取指周期

1. 当前指令地址送至存储器地址寄存器，(PC)$\rightarrow$MAR
2. CU发出控制信号，经控制总线传到主存，要求读取，1$\rightarrow$R
3. 主存根据MAR中存储的地址找到相应的存储单元，将数据（指令）经由数据总线送入MDR，M(MAR)$\rightarrow$MDR
4. 将MDR中的内容（指令）送入IR，(MDR)$\rightarrow$IR
5. **CU发出控制信号，形成下一条指令地址，(PC)+1$\rightarrow$PC**

即取值周期结束后，PC+1

#### 间址周期

需要间接寻址的指令才有间址周期。

1. 将指令的地址码送入MAR，Ad(IR)$\rightarrow$MAR或Ad(MDR)$\rightarrow$MAR
2. CU发出控制信号，经控制总线传到主存，要求读取，1$\rightarrow$R
3. 主存根据MAR中存储的地址找到相应的存储单元，将数据（指令）经由数据总线送入MDR，M(MAR)$\rightarrow$MDR
4. 将操作数的真实地址送至指令的地址码字段，(MDR)$\rightarrow$Ad(IR)

#### 执行周期

1. 取操作数
2. 根据IR中指令字的操作码，通过ALU操作产生执行结果

#### 中断周期

**在执行周期结束后响应中断（如果有），进入中断周期**

中断：暂停当前任务去完成其他任务。为了能够恢复当前任务，需要保存断点。一般使用堆栈来保存断点，进栈时先修改SP再存入数据。

1. CU控制SP减1，再把修改后的SP中的地址送入MAR。(SP)-1$\rightarrow$SP,(SP)$\rightarrow$MAR
2. CU发出控制信号，经控制总线传到主存，要求写入，1$\rightarrow$W
3. 将断点（PC内容）送入MDR，(PC)$\rightarrow$MDR
4. CU控制将中断服务程序的入口地址（由向量地址形成部件产生）送入PC，向量地址$\rightarrow$PC

### 指令执行方案

#### 方案一：单指令周期

即指令周期是等长的，具体耗时长度由所有指令中耗时最长的指令决定。

指令之间串行执行

#### 方案二：多指令周期

对不同类型的指令选用个不同的执行步骤来完成。

指令之间串行执行；可选用不同个数的时钟周期来完成不同指令的执行过程。

需要更复杂的硬件设计。

#### 方案三：流水线方案

在每一个时钟周期启动一条指令，尽量让多条指令同时运行，但各自处在不同的执行步骤中。如同一时间，指令A正在执行阶段，指令B正在取指阶段。

指令之间并行执行。

## 5.3 数据通路

数据通路的基本结构有以下三种

- CPU内部单总线方式
- CPU内部三总线方式
- 专用数据通路方式

### CPU内部单总线结构

![image-20221022222813477](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20221022222813477.png)

#### 寄存器之间的数据传送

描述清楚数据流向和控制信号，如把PC内容送到MAR，则实现传送操作的流程及控制信号为：

(PC)$\rightarrow$Bus，$PC_{out}$有效，PC内容送总线

Bus$\rightarrow$MAR，$MAR_{in}$有效，总线内容送MAR

#### 主存与CPU之间的数据传送

#### 执行算术或逻辑运算

ALU本身无存储功能，计算两个数时要求两个输入端同时有效。

一个操作数先送至暂存器保存，暂存器连接ALU的一个输入端并始终有效；另一个操作数通过总线直接送到ALU的另一个输入端。

运算结果暂存在另一个暂存器中

### 专用数据通路

![image-20221022221745203](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20221022221745203.png)

（1）d寄存器有+1标志，所以是PC；c寄存器单向指向主存，所以是MAR；b既指向PC又指向微操作信号发生器，所以是IR；a与主存、ALU是双向的，所以是MDR。

（2）(PC)到MAR，M(MAR)到MDR，MDR到IR，完成取指

（3）取：地址存储在MAR中，CPU向主存发出读控制命令，M(MAR)到MDR，(MDR)再到ALU再到ACC；存：ALU计算完毕后将结果打入ACC，(ACC)再到MDR，MAR存储要写入的地址，CPU向主存发出写控制命令，(MDR)到M(MAR)

## 5.4 硬布线控制器的设计

### CPU的控制方式

- 同步控制方式：
- 系统有一个统一的时钟，所有的控制信号均来自这个统一的时钟信号，长度以最长的微操作序列和最繁琐的微操作为标准。
- 采用完全统一的、具有相同时间间隔和相同数目的节拍作为机器周期
- 控制电路简单，但运行速度慢
- 异步控制方式：
- 各部件按自身固有的速度工作，通过应答方式进行联络
- 运行速度快，但控制电路复杂
- 联合控制方式：
- 介于同步、异步之间的一种折中。
- 大部分采用同步控制、小部分采用异步控制

### 设计原理

根据**指令操作码**、**当前的机器周期**、**节拍信号**、**机器状态条件**，即可确定在目前这个节拍下应该发出哪些微命令。

- 指令操作码根据指令寄存器中的指令由操作码译码器产生
- 当前机器周期用四个触发器（集成在CU中）表示：FE（取指周期）、IND（间址周期）、EX（执行周期）、INT（中断周期）；四个触发器哪个为1，就表示当前处于哪个机器周期。
- 节拍信号由机器主频CLK经过节拍发生器产生
- 机器状态条件来源比较广泛，可能来自运算器的PSW、ACC的符号位等，也可能来自I/O设备、主存

CU内部电路综合上述输入信号，直接产生相应的控制信号，也即一个微命令。

> CU内部电路如何综合输入信息产生控制信号？

如微操作指令$M(MAR)\rightarrow MDR$，它会在以下情况出现：

- 取指阶段的$T_1$节拍（$T_0$节拍是$(PC)\rightarrow MAR$）；
- 间址阶段的$T_1$节拍（前提：要执行的操作是ADD、STA、LDA、JMP、BAN其中之一）
- 执行阶段的$T_1$节拍（前提：要执行的操作是ADD或LDA）

所以该微命令的逻辑表达式是： $$ FE \cdot T_1\+IND\cdot T_1(ADD+STA+LDA+JMP+BAN)\+EX\cdot T_1(ADD+LDA) $$

### 设计步骤

1. 分析每个阶段的微操作序列（取指、间址、执行、中断四个阶段）
2. 选择CPU的控制方式（定长机器周期还是不定长机器周期？每个机器周期安排几个节拍？）
3. 安排微操作时序（如，如何用3个节拍完成整个机器周期内的所有微操作？哪些微操作可以在同一个节拍内并行？）
4. 原则一：微操作的先后顺序不得随意更改
5. 原则二：被控对象不同的微操作尽量安排在一个节拍内完成
6. 原则三：占用时间较短的微操作尽量安排在一个节拍内完成，并允许有先后顺序（如被控对象是CPU内部寄存器之间时）
7. 电路设计（确定每个微操作命令的逻辑表达式，并用电路实现）
8. 列出操作时间表
9. 写出微操作命令的最简表达式
10. 画出逻辑图

### 特点

指令越多，设计和实现就越复杂，一般用于RISC

如果扩充一条新的指令，则控制器的设计就需要大改，扩充指令困难

由于使用纯硬件实现控制，执行速度非常快，微操作控制信号由组合逻辑电路即时产生。

## 5.5 微程序控制器

### 微程序控制器的设计思路

一条机器指令对应一个微程序，一个微程序包含多条微指令，一条微指令完成系列微操作/微命令。

- 微命令/微操作：控制部件向执行部件发出的各种控制命令，是构成控制序列的最小单位。如打开或关闭某个控制门的电位信号等。微操作是微命令的执行过程
- 相容微命令：可以同时产生、共同完成某一些微操作的微命令
- 互斥微命令：机器中不允许同时出现的微命令
- 微指令：微指令是若干微命令的集合。一条微指令包含操作控制字段和顺序控制字段，前者用于产生各种操作控制信号，后者用于产生下一条要执行的微指令地址
- 微周期：从控制存储器中读取一条微指令并执行响应的微操作所需的时间
- 控制存储器：用于存放微程序，在CPU内部，用ROM实现
- 微程序：微程序是微指令的有序集合。一条机器指令对应一个微程序。

### 微程序控制器的组成和工作原理

> 微程序从哪来？当前执行的微指令的地址存放在哪里？取出的微指令又存放在哪里？

微程序由厂家在制造时编制好并写入到**控制存储器CM（可用ROM构成）**中。

微指令基本格式包括操作控制字段和顺序控制字段。操作控制字段表示微指令所需要完成的微操作有哪些；顺序控制字段指明下一条微指令（在CM中的）的地址。

**微地址寄存器CMAR/$\mu$PC**：用于接收微地址形成部件送来的微地址，为在CM中读取微指令作准备。

**地址译码器**：将地址码转化为存储单元控制信号

**微指令寄存器CMDR/$\mu$IR**：用于存放从CM中取出的微指令，它的位数与微指令字长相等。

**微地址形成部件**：产生初始微地址和后继微地址，以保证微指令的连续执行。

**顺序逻辑**：时钟信号、状态标志位等，还可以根据微地址中的寻址特征位判断是否要跳过间址周期

### 公用微程序

每条指令在取指周期、间址周期和中断周期中所要完成的微操作其实是相同的，因此这三个周期对应的微程序只在CM中存储一份即可。而不同指令在执行周期所要执行的微程序则可能不同，那么也为LDA、STA等指令对应的微程序各准备一份存储在CM中，不同指令只需要在公用的微程序结束后转到不同的执行周期微程序起始地址即可。

因此，如果某指令系统中有n条机器指令，则CM中微程序段的个数至少是n+1个。其中n为不同机器指令对应的不同执行周期微程序；1为公用的取指周期微程序。因为是“至少”，所以假设没有间址周期和中断周期。

一条机器指令实际上至少包含了取指周期微程序+执行周期微程序这2个微程序，但它们在逻辑上是一个整体，因此认为“**一条指令对应一个微程序**”也是正确的。

### 微指令的设计

#### 微指令种类

1. 水平型微指令

一条微指令能定义多个可并行的微命令

微程序短（微指令数量少），执行速度快；单条微指令长，编写微程序较麻烦。

1. 垂直型微指令

一条微指令只能定义一个微命令，由微操作码字段规定具体功能

微程序长，执行速度慢，工作效率低；单条微指令短、简单、规整，便于编写微程序

1. 混合型微指令

在垂直型的基础上增加一些不太复杂的并行操作。

微指令较短，仍便于编写；微程序也不长，执行速度加快。

#### 微指令的编码方式

1. 直接编码方式

在微指令的操作控制字段中，每一位代表一个微操作命令

优点：简单、直观，执行速度快，操作并行性好

缺点：微指令字长过长，n个微命令就要求微指令的操作字段有n位，造成控存容量极大。

1. 字段直接编码方式

将微指令的控制字段分成若干“段”，每段经**译码**后发出控制信号

分段原则：

- 互斥性微命令分在同一段内，相容性微命令分在不同段内
- 每个小段中包含的信息位不能太多，否则将增加译码线路的复杂性和译码时间
- **一般每个小段还要留出一个状态，表示本段不发出任何微命令**，因此，当某字段的长度为3位时，最多只能表示7个互斥的微命令。通常用000表示不操作

优点：可以缩短微指令字长

缺点：要通过译码电路后再发出微命令，因此比直接编码方式慢

1. 字段间接编码方式

一个字段的某些微命令需由另一个字段中的某些微命令来解释，由于不是靠字段直接译码发出的微命令，故称为字段间接编码，又称隐式编码。

优点：可进一步缩短微指令字长

缺点：削弱了微指令的并行控制能力

#### 微指令的地址形成方式

- 方式一：由微指令的下一地址字段指出

微指令格式中设置一个下一地址字段，由该字段直接指出后继微指令的地址。这种方式又称为断定方式

- 方式二：根据机器指令的操作码形成

当机器指令取至指令寄存器后，微指令的地址由操作码经微地址形成部件形成

- 方式三：增量计数器法

(CMAR)+1 → CMAR

- 方式四：分支转移

此方式下微指令格式中有三个字段：操作控制、转移方式和转移地址，转移方式字段指明判别条件，转移地址指明转移成功后的去向

- 方式五：通过测试网络

测试网络即一些逻辑电路，根据顺序逻辑等信号决定下一微地址

- 方式六：由硬件产生微程序入口地址

第一条微地址和中断周期首地址由专门硬件产生（用专门的硬件存储取指周期微程序、中断周期微程序的首地址）

### 微程序控制单元的设计

1. 分析每个阶段的微操作序列
2. 写出对应机器指令的微操作命令及节拍安排

（1）写出每个周期所需要的微操作

（2）补充微程序控制器特有的微操作：

- 取指周期：Ad(CMDR) → CMAR、 OP(IR) → CMAR（转入执行周期）
- 执行周期：Ad(CMDR) → CMAR
- 确定微指令格式

根据微操作个数决定采用何种编码方式，以确定微指令的操作控制字段的位数；

根据CM中存储的微指令总数，确定微指令的顺序控制字段的位数

根据操作控制字段的位数和顺序控制字段的位数，确定微指令字长

1. 编写微指令码点

根据操作控制字段每一位代表的微操作命令，编写每一条微指令的码点。

## 5.6 硬布线与微程序的比较

![image-20220719011027795](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220719011027795.png)

## 5.7 指令流水线

### 指令执行的方式

假设一条指令的执行构成由取指、分析、执行三个阶段构成，且耗时都相等，为$t$

1. 顺序执行方式

每条指令依次完成，即指令一完成取指、分析、执行后再开始指令二的取指、分析、执行……则顺序执行$n$条命令的总耗时$T=n\times 3t=3nt$

1. 一次重叠执行方式

![image-20220719012304959](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220719012304959.png)

在指令一处于执行阶段时，指令二同时进行取指阶段。在时间轴上，指令与指令之间只有在这部分才会有时间上的重叠，所以是一次重叠。一次重叠执行方式的总耗时$T=3t+(n-1)\times2t$

1. 二次重叠执行方式

![image-20220719012239503](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220719012239503.png)

总耗时$T=3t+(n-1)\times t=(2+n)t$

### 流水线的表示方法

1. 指令执行过程图

用于分析指令执行过程以及影响流水线的因素

![image-20220719015137334](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220719015137334.png)

1. 时空图

用于分析流水线的性能

![image-20220719015212053](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220719015212053.png)

### 流水线的性能指标

1. 吞吐率

单位时间内流水线所完成的任务数量，或是输出结果的数量

设任务数为$n$；完成$n$个任务的总用时为$T_k$；则流水线吞吐率（TP）的最基本公式为 $$ TP=\frac{n}{T_k} $$ 设现有$n$条指令，指令周期都相等，都分为$k$个机器周期，其中一个机器周期只包含一个时钟周期$\Delta t$，则流水线的吞吐率为 $$ TP=\frac{n}{(k-1)\Delta t+n\Delta t}=\frac{n}{(k+n-1)\Delta t} $$ 其中$(k-1)\Delta t$是流水线装入阶段的耗时；在装入阶段结束后，每经过一个$\Delta t$都会完成一条指令，共会完成$n$条指令。

1. 加速比

完成同样一批任务，不使用流水线所用的时间与使用流水线所用的时间之比。

设$T_0$为不使用流水线时的耗时，$T_k$为使用流水线时的耗时，则流水线加速比($S$)的基本公式为 $$ S=\frac{T_0}{T_k} $$

1. 效率

流水线的设备利用率。在时空图上，流水线的效率为完成$n$个任务占用的时空区有效面积与$n$个任务所用的时间与$k$个流水段所围成的时空区总面积之比。

![image-20220719020422253](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220719020422253.png)

### 指令流水线的影响因素和分类

#### 机器周期的设置

MIPS架构下，指令周期分为取指、译码、执行、访存、写回共5个机器周期，即使某些指令实际上不需要其中的某些机器周期，也必须等待该机器周期的时间。

为方便流水线的设计，将每个阶段的耗时统一为以最长耗时为准。

流水线每一个功能段部件后都由一个缓冲寄存器，或称为锁存器，其作用是保存本流水线段的执行结果，提供给下一流水段使用。

Cache分为两个彼此独立的部件，指令Cache和数据Cache，由于Cache命中率相当高，在这里我们默认所需的指令/数据都可以直接从Cache取得。

指令Cache和数据Cache彼此独立，使得取指阶段和访存阶段可以并行。

在指令译码阶段，除了对操作码进行译码之外，还要将操作数从通用寄存器中取出放到锁存器里（RISC架构下，操作数从主存取出后先存储在通用寄存器）。若指令的寻址方式为立即寻址，则将立即数放到专门的Imm寄存器。

#### 影响流水线的因素

1. 结构相关（资源冲突）

由于多条指令在同一时刻争用同一资源而形成的冲突。

![image-20220719184303682](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220719184303682.png)

解决方法：

- 前一指令访存时，后一相关指令暂停一周期
- 资源重复配置：如互相独立的指令Cache和数据Cache
- 数据相关

在一个程序中，存在必须等前一条指令执行完才能执行后一条指令的情况，则这两条指令即为数据相关

- 写后读（RAW）相关：当前指令将数据写入寄存器后，下一条指令才能从该寄存器读取数据
- 读后写（WAR）相关：当前指令读出数据后，下一条指令才能写该寄存器
- 写后写（WAW）相关：当前指令写入寄存器后，下一条指令才能写该寄存器

```
add r1,r2,r3
sub r4,r1,r3
and r6,r1,r7
or r8,r1,r9
xor r10,r1,r11
```

如上述指令中，r1寄存器被相继使用，指令彼此之间数据相关。

![image-20220719202007338](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220719202007338.png)

解决办法：

- 把遇到数据相关的指令及其后续指令都暂停一至几个时钟周期，直到数据相关问题消失后再继续执行。可分为硬件阻塞和软件插入（插入空指令）两种方法。

![image-20220719202059543](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220719202059543.png)

- 数据旁路技术：例如，在同一个ALU内，将前一指令的结果直接送到另一个寄存器中，供下一条需要用到ALU的指令直接使用这个数据。
- 编译优化：通过编译器调整指令顺序来解决数据相关。即把后续的无数据相关的指令提前执行。
- 控制相关（控制冲突）

当流水线遇到转移指令和其他改变PC值的指令而造成断流（导致已装入的指令实际上不应该执行）时，会引起控制相关

解决方法：

- 转移指令分支预测。简单预测（永远猜True或False）、动态预测（根据历史情况动态调整）
- 预取转移成功和不成功两条控制流上的目标指令（也就是CS:APP上说的两边都执行，再根据转移方向对结果作取舍）
- 加快和提前形成条件码（就像加法器里的超前进位）
- 提高转移方向的猜准率

#### 流水线的分类

1. 部件功能级、处理机级和处理机间级流水线

根据流水线使用的级别的不同分类。

部件功能级流水线就是将复杂的算术逻辑运算组成流水线工作方式。如浮点加法分为求阶差、对阶、尾数相加和结果规格化4个子过程。

处理机级流水就是把一条指令解释过程分为多个子过程。

处理机间流水是一种宏流水，其中一个处理机完成某一专门任务，各个处理机所得到的结果存放在与下一个处理机所共享的存储器中。

1. 单功能流水线和多功能流水线

按流水线可以完成的功能，流水线可分为单功能流水线和多功能流水线。

单功能流水线指只能实现一种固定的专门功能的流水线。

多功能流水线指通过各段间的不同连接方式可以同时或不同时地实现多种功能的流水线（如指令流水线）

1. 动态流水线和静态流水线

按同一时间内各段之间的连接方式，流水线可分为静态流水线和动态流水线。

静态流水线指同一时间内，流水线的各段只能按同一种功能的连接方式工作。如浮点加法流水线。

动态流水线指同一时间内，当某些段正在实现某种运算时，另一些段却正在进行另一种运算。

1. 线性流水线和非线性流水线

按流水线的各个功能段之间是否有反馈信号，流水线可分为线性流水线和非线性流水线

#### 流水线的多发技术

1. 超标量技术

每个时钟周期内可并发多条独立指令，需要配置多个功能部件，不能调整指令的执行顺序。

通过编译优化技术，把可并行执行的指令搭配起来。

![image-20221024093009670](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20221024093009670.png)

1. 超流水线技术

![image-20220719235954194](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220719235954194.png)

通过提高流水线主频的方式提升流水线性能

但级数越多，用于流水寄存器的开销就越大，所以不是越多越好

在一个机器周期内再分段，在一个机器周期内一个功能部件使用多次（时分复用）。不能调整指令的执行顺序。

超流水线CPU在流水线充满后，每个时钟周期还是完成一条指令，CPI=1.

靠编译程序解决优化问题

1. 超长指令字技术

![image-20220720000301594](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220720000301594.png)

由编译程序挖掘出指令间潜在的并行性，将多条能并行操作的指令组合成一条具有多个操作码字段的超长指令字（可达几百个比特）

对Cache容量要求更大。

### 五段式指令流水线

要点总结：

- IF阶段有IF阶段的锁存器，用于存放取出的指令数据，并需要等待ID阶段开始来取走锁存器中的内容。
- ID阶段既取走IF段锁存器的指令进行译码，又从通用寄存器中取走需要的数据，并放到ID段锁存器
- 对于RISC处理器，只有LOAD指令和STORE指令才能访问主存。且从主存中取出的数据要等到WB阶段才会真正写入到寄存器中。
- 运算指令的运算结果也要等到WB阶段才会真正写入到寄存器中
- PC+1通常发生在IF段结束后
- **条件转移指令中对PC值的修改发生在M段**而非WB段
- **无条件指令中对PC值的修改发生在EX阶段**

![image-20220720004346384](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20220720004346384.png)

LOAD指令中，从主存取出的数需要等到WB阶段才会写入到寄存器中。ID阶段既完成指令译码工作，又要完成从寄存器取出相关数据的操作。因此I3的ID阶段需要等到I1和I2指令的WB阶段结束后才能开始。即，I3与I1和I2存在数据相关。

因为I3的ID阶段被推迟，则I3在IF阶段完成后I3指令数据仍占用着IF段锁存器，I4的IF阶段因此也无法紧接着开始，只能推迟到I3的ID阶段开始时。

## 5.8 多处理器

### SISD、SIMD、MIMD

- 单指令流单数据流结构（SISD）

传统串行计算机结构，通常只包含一个处理器和一个存储器，处理器在一段时间内仅执行一条指令。有些SISD计算机采用流水线的方式

- 单指令流多数据流（SIMD）

一个指令流同时对多个数据流进行处理，又称**数据级并行**技术。由一个指令控制部件、多个处理单元组成。不同处理单元执行的同一条指令所处理的数据不同。

在使用for循环处理数组时最有效，如一条分别对16对数据进行运算的SIMD指令若在16个ALU中同时运算，则只需要一次运算时间。在使用case或switch语句时效率最低

- 向量处理器：SIMD的变体，是一种实现了直接操作一维数组（向量）指令集的CPU。
- 多指令流单数据流（MISD）

同时执行多条指令，处理同一个数据。但实际上不存在这样的计算机

- 多指令流多数据流（MIMD）
- 线程级并行或线程级以上并行，与数据级并行相比并行程度更高
- 多计算机系统（消息传递MIMD）：每个节点都有各自的私有存储器，具有独立的主存地址空间。节点之间只能通过消息传递方式进行数据传送。
- 多处理器系统（共享存储MIMD）：具有共享的单一地址空间，通过存取指令访问系统中的所有存储器

### 硬件多线程

即在OS中学习线程时所说的，为了降低线程切换过程中的开销，为每个线程提供单独的通用寄存器组、单独的程序计数器，从而线程切换只需激活选中的寄存器，而不必把数据先搬到主存来腾出寄存器位置。

#### 细粒度多线程

处理器能在**每个时钟周期内**切换线程

多个线程之间轮流交叉执行指令。这多个线程之间指令不相关，可以乱序并行执行。

#### 粗粒度多线程

处理器仅在**一个线程出现了较大开销的阻塞时**切换线程，如Cache缺失

发生流水线阻塞时，要先清除被阻塞的流水线，重载后再执行新线程的指令。切换开销比细粒度多线程更大

#### 同时多线程

在实现指令级并行的同时，实现线程级并行。

即，在同一个时钟周期中，它发射多个不同线程中的多条指令

Intel处理器中的超线程技术就是同时多线程

![image-20221024111750896](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x05%20%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/image-20221024111750896.png)

### 多核处理器

将多个处理单元集成到单个CPU中，每个处理单元称为一个核

每个核可以有自己的Cache，也可以共享同一个Cache

多核上的多个线程是在物理上并行执行的；而单核上的多线程实际是交错执行

### 共享内存多处理器

共享内存多处理器（SMP）：具有共享的单一物理地址空间的多处理器

处理器通过存储器中的共享变量相互通信，通过存取指令访问任何存储器的位置。

- UMA（统一存储访问）：每个处理器对所有存储单元的访问时间大致相同，与处理器和访存单元都无关
- NUMA（非统一存储访问）：某些访存请求要比其他的要快，取决于处理器和要访问的字。这是因为主存被分割并被分配给了同一机器上的不同处理器或内存控制器

NUMA解决了多核、多CPU争用前端总线的问题，它令每个CPU都有独立的内存控制器，且每个CPU都独立连接到一部分内存。直连的内存被称为本地内存。通过QPI总线访问其他CPU直连的内存称为远程内存。

访问本地内存明显要快于访问远程内存。

操作共享变量时需要同步，常用方法是对共享变量加锁。

# 第六章 总线

## 6.1 总线概述

多根信号线组成一根总线，同一时刻只能有一个部件发送数据，但可有多个部件接受数据。

### 总线的定义

总线是一组能为多个部件分时共享的公共信息传送线路。

- 分时：同一时刻只允许有一个部件向总线发送信息
- 共享：总线上可以挂接多个部件，各个部件之间相互交换的信息都可以通过这组线路分时共享

为了解决I/O设备和主机之间连接的灵活性问题，从分散连接发展为总线连接。

### 总线的特性

1. 机械特性：尺寸、形状、管脚数、排列顺序
2. 电气特性：传输方向和有效的电平范围
3. 功能特性：每根传输线的功能（传输什么？地址or数据or控制？）
4. 时间特性：信号的时序关系

### 总线的分类

#### 按数据传输格式

- 串行总线

每次只能传一位（如USB）

优点：只需要一条传输线，成本低，广泛应用于长距离传输，节省布线空间

缺点：在数据发送和接收时要进行拆卸和装配，要考虑串行、并行转换的问题

- 并行总线

每次可以传多位

优点：总线的逻辑时序比较简单，电路实现起来比较容易

缺点：信号线数量多，占用更多的布线空间；长距离传输成本高昂；工作频率较高时，信号线彼此之间会产生严重干扰。因此并行总线不一定比串行总线更快

#### 按总线功能

- 片内总线

片内总线是CPU芯片内部的总线。是CPU芯片内部寄存器之间、寄存器与ALU之间的公共连接线。

- 系统总线

系统总线是计算机系统内各功能部件之间相互连接的总线。

- 数据总线：用来传输数据信息，双向，位数与机器字长、存储字长有关
- 地址总线：指出数据所在的主存单元或I/O端口的地址，单向，位数与主存地址空间和I/O设备数量有关（如统一编址的情况）。
- 控制总线：传输的是控制信息，包括CPU送出的控制命令和主存（或外设）返回CPU的反馈信号。对于单根传输线而言是单向的，对于总线整体而言是双向的。
- I/O总线

用于连接中低速的I/O设备，通过I/O接口与系统总线相连，目的是将低速设备与高速总线分离，以提升总线的系统性能。如USB、PCI总线

- 通信总线

用于计算机系统之间或计算机系统与其他系统（如远程通信设备、测试设备）之间信息传送的总线，通信总线也称为外部总线。

### 系统总线的结构

- 单总线结构
- CPU、主存、I/O设备（通过I/O接口）都连接在一组总线上，允许I/O设备之间、I/O设备和CPU之间或I/O设备与主存之间直接交换信息
- 优点：结构简单、成本低、易于接入新的设备
- 缺点：带宽低、负载重，多个部件只能争用唯一的总线，且不支持并发传送操作（即多组部件之间同时传送数据）
- 双总线结构
- 有两条总线，一条是主存总线，用于CPU、主存和通道之间进行数据传送，速度较快；另一条是I/O总线，用于多个外部设备与通道之间进行数据传送，速度较慢
- 具有通道。通道是具有特殊功能的处理器，能对I/O设备进行统一管理。通道程序放在主存中
- 优点：将较低速的I/O设备从单总线上分离出来，实现存储器总线和I/O总线分离
- 缺点：需要增加通道等硬件设备
- ![image-20221025101147979](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x06%20%E6%80%BB%E7%BA%BF/image-20221025101147979.png)
- 三总线结构
- 有三条总线，分别为主存总线、I/O总线和直接内存访问DMA总线。磁盘机等高速外设直接通过DMA总线与主存之间进行数据传输；打印机、键盘等低速外设则通过I/O总线与CPU之间进行数据传输。
- 优点：提高了I/O设备的性能，使其更快地响应命令，提高系统吞吐量
- 缺点：系统工作效率较低，因为三条总线同一时间只能有一条在工作。

![image-20221025101139672](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x06%20%E6%80%BB%E7%BA%BF/image-20221025101139672.png)

- 四总线结构

![image-20220720145746049](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x06%20%E6%80%BB%E7%BA%BF/image-20220720145746049.png)

- 有四条总线，分别为CPU总线（CPU和Cache）、系统总线、高速总线和扩充总线。具有桥接器，用于连接不同的总线，具有数据缓冲、转换和控制功能。

## 6.2 总线的性能指标

### 传输周期/总线周期

一次总线操作所需的时间（包括申请阶段、寻址阶段、传输阶段和结束阶段），通常由若干个总线时钟周期构成

### 总线时钟周期

即机器的时钟周期

一个总线周期可能包含多个、一个、几分之一个时钟周期（即在一个时钟周期内可以完成多次总线操作）

### 工作频率

总线上各种操作的频率，为总线周期的倒数。

若总线周期=N个时钟周期，总线的工作频率=时钟频率/N

实际上指**一秒传送几次数据**

### 总线时钟频率

即机器的时钟频率，为时钟周期的倒数

若时钟周期为T，则时钟频率为1/T

实际上指一秒内有多少个时钟周期

### 总线宽度

又称总线位宽，指总线上同时能够传输的数据位数

通常是指数据总线的根数，如32根称为32位总线

### 总线带宽

单位时间内总线可传输的数据的位数，通常用每秒传送信息的字节数来衡量，单位B/s

是指总线本身所能达到的最高传输速率

在计算实际的有效数据传输率时，要用实际传输的数据量除以耗时

> 例：某同步总线采用数据线和地址线复用方式，其中地址/数据线有32根，总线时钟频率为66MHz，每个时钟周期传送两次数据。
>
> （1）该总线的最大数据传输率（总线带宽）是多少？
>
> （2）若该总线支持突发（猝发）传输方式，传输一个地址占用一个时钟周期，则一次“主存写”总线事务传输128位数据所需要的时间至少是多少？

（1）一个时钟周期的时长为$\frac{1}{66\times10^6}s$，一秒共有$66\times10^6$个时钟周期，一个时钟周期传送两次数据共64bit，则一秒传输$66\times 10^6\times64bit=66\times8\times10^6byte$，故总线带宽为$528MB/s$

（2）由于支持突发传输方式，只需传输一次地址就能连续得到128位数据。发送首地址需要占用一个时钟周期，128位数据需传送4次，占用两个时钟周期，三个时钟周期的总时间为$1/22\times10^{-6}s=45\times10^{-9}s=45ns$。

### 总线复用

总线复用是指一种信号线在不同的时间传输不同的信息。这样就可以使用较少的线传输更多的信息，从而节省空间成本

### 信号线数

地址总线、数据总线、空间总线3种总线数的总和

## 6.3 总线仲裁

### 总线仲裁的基本概念

主设备：获得总线控制权的设备

从设备：被主设备访问的设备，只能响应从主设备发来的各种总线命令

总线仲裁：多个主设备同时竞争主线控制权时，以某种方式选择一个主设备优先获得总线控制权

分类：集中仲裁方式、分布仲裁方式

### 集中仲裁

#### 工作流程

1. 主设备发出请求信号
2. 若多个主设备同时要使用总线，则由总线控制器的判优、仲裁逻辑按一定的优先等级顺序确定哪个主设备能使用总线
3. 获得总线使用权的主设备开始传送数据

#### 链式查询方式

总线中设有三根信号线，分别为BG（总线允许）、BR（总线请求）、BS（总线忙）

设备先向BR线发送信号，总线控制部件向BG线发送信号，BG线所经过的第一个发送了请求的设备获得总线控制权，同时该设备向BS线发送信号。总线控制部件收到BS线的信号，得知总线控制权已经分配完毕，撤销BG线信号。

优先级：离总线控制器越近，优先级越高，反之越低

优点：优先级固定，只需要很少几根控制线就能按一定优先次序实现总线控制

缺点：对硬件电路的故障敏感（BG线信号经过了某个损坏的设备无法继续向下传递），且优先级不能改变；饥饿现象。

#### 计数器查询方式

相对链式查询方式多了一组设备地址线，同时每个设备都有一个编号，少了一根总线响应线BG；设备间共用一根BR线。总线控制部件中增加一个计数器。

计数器查询方式实际上就是轮询，计数器当前的计数是多少，就询问对应编号设备是否需要使用总线，是则置BS线信号并暂停计数；否则继续计数询问下一个设备。

优点：计数初始值可以改变优先次序。若计数总是从上一次的终点开始，则设备使用总线的优先级相等。若计数每次从“0”开始，则设备优先级按顺序排列，固定不变。对电路故障没有链式敏感。

缺点：增加了控制线数；控制电路比链式查询复杂

#### 独立请求方式

每个设备都有一对BG线和BR线连接到总线控制部件；有一条公用的BS线；总线控制部件中设置有排队器。

当设备需要使用总线时，则通过BR线发送请求信号。总线控制部件会对请求信号进行排队，按一定的优先次序决定哪个部件的请求被批准，并发送对应的BG信号，被分配到总线控制权的部件对BS线发送信号。

优点：响应速度快，BG信号直接从控制器发送到对应设备，不必在设备间传递或查询；对优先次序的控制灵活

缺点：控制线数量多，n个设备需要2n+1条控制线；总线的控制逻辑更加复杂。

### 分布仲裁

特点：不需要中央仲裁器，每个潜在的主模块都有自己的仲裁器和仲裁号，多个仲裁器竞争使用总线。

1. 当设备有总线请求时，就把自己的仲裁号发送到共享的仲裁总线
2. 每个仲裁器从仲裁总线上得到仲裁号，与自己的仲裁号比较
3. 若仲裁总线上的号优先级高，则该仲裁器发出的总线请求不被响应，发出的仲裁号也会被撤销
4. 获胜者的仲裁号保留在仲裁总线上

## 6.3 总线操作和定时

### 总线事务

#### 请求阶段

需要使用总线的主模块（或主设备）提出申请

#### 仲裁阶段

总线仲裁机构决定将下一个传输周期的总线使用权授予某个申请者

#### 寻址阶段

获得总线控制权的设备向总线发出访问地址，启动参与本次传输的从模块

#### 传输阶段

主设备与从设备之间进行数据交换

**突发/猝发传送方式**：能够进行连续成组数据的传送。寻址阶段发送的是连续数据单元的首地址，一组数据全部传送完毕后再释放总线

#### 结束阶段

主设备的有关信息均从系统总线上撤除，让出总线控制权

### 定时

#### 同步定时方式（同步通信）

总线传输的各阶段按同一的时钟节拍进行

若总线从设备未能在规定的节拍之前准备好数据并在规定的节拍发出，则数据传输会失败

优点：传送速度快，具有较高的传输速率；总线控制逻辑简单

缺点：主从设备属于强制性同步；不能及时进行数据通信的有效性检验，可靠性较差

适用于总线长度较短及总线所接部件的存取时间比较接近的系统

#### 异步定时方式（异步通信）

优点：总线周期长度可变，能保证两个工作速度相差很大的部件或设备之间可靠地进行信息交换，自动适应时间的配合

缺点：比同步控制方式稍复杂，速度比同步定时方式慢

- 不互锁

主设备发出请求信号，等待一定时间后直接撤销，不需要从设备的响应

从设备发出回答信号，等待一定时间后直接撤销，不需要主设备确认

速度最快，可靠性最差

![image-20220720191522801](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x06%20%E6%80%BB%E7%BA%BF/image-20220720191522801.png)

- 半互锁

主设备发出请求信号，必须接收到从设备的回答信号后才能撤销

从设备发出回答信号，等待一定时间后直接撤销，不需要主设备确认

![image-20220720191530846](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x06%20%E6%80%BB%E7%BA%BF/image-20220720191530846.png)

- 全互锁

主设备发出请求信号，必须接收到从设备的回答信号后才能撤销

从设备发出回答信号，必须等待主设备的请求信号撤销后才能撤销

最可靠，速度最慢

![image-20220720191541171](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x06%20%E6%80%BB%E7%BA%BF/image-20220720191541171.png)

#### 半同步通信

在统一时钟的基础上，增加一个“等待”响应信号，当从设备数据来不及准备时，让总线传输周期延长。

![image-20220720201259604](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x06%20%E6%80%BB%E7%BA%BF/image-20220720201259604.png)

#### 分离式通信

分离式通信的一个总线传输周期分为两个子周期。

- 子周期1：主模块申请占用总线，使用完后放弃总线的使用权
- 子周期2：从模块申请占用总线，将各种信息送至总线上

特点：

1. 各模块均有权申请占用总线
2. 采用同步方式通信，不等对方回答
3. 各模块准备数据时，不占用总线
4. 总线利用率提高

## 6.4 总线标准

| 总线标准 | 工作频率 | 数据线 | 最大速度    | 特点     |
| :------- | :------- | :----- | :---------- | :------- |
| ISA      | 8MHz     | 8/16   | 16MB/s      | 系统总线 |
| EISA     | 8MHz     | 32     | 32MB/s      | 系统总线 |
| VESA     | 33MHz    | 32     | 132MB/s     | 局部总线 |
| PCI      | 33/66MHz | 32/64  | 528MB/s     | 局部总线 |
| AGP      | -        | -      | X8：2.1GB/s | 局部总线 |
| PCI-E    | -        | -      | 10GB/s以上  | 串行     |

### 设备总线标准

| 总线标准   | 工作频率 | 数据线 | 最大速度 | 特点           |
| :--------- | :------- | :----- | :------- | :------------- |
| RS-232C    | -        | -      | 20Kbps   | 串行通信总线   |
| SCSI       | -        | -      | 640MB/s  | 智能通用接口   |
| PCMCIA     | -        | -      | 90Mbps   | 便携设备接口   |
| USB        | -        | -      | 1280MB/s | 设备总线、串行 |
| IDE（ATA） | -        | -      | 100MB/s  | 硬盘光驱接口   |
| SATA       | -        | -      | 600MB/s  | 串行硬盘接口   |

![image-20220720204624395](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x06%20%E6%80%BB%E7%BA%BF/image-20220720204624395.png)

### 为何串行总线取代并行总线

并行总线：用m根线每次传送m个比特，通常采用同步定时方式，由于线间信号干扰，工作频率不能太高。各条线之间不能有长度差，长距离并行传输时工艺难度大

串行总线：用两根线每次传输一个比特，用“差模信号”（即两根线之间的电压差）表示1/0，通常采用异步定时方式，总线工作频率可以很高。通常基于包传输，包与包之间有先后关系。

# 第七章 I/O系统

## 7.1 I/O系统基本概念

I/O接口：又称I/O控制器、设备控制器，负责协调主机与外部设备之间的数据传输。就是一块芯片，集成在主板上。

### I/O控制方式

> CPU如何知道键盘I/O的完成？

#### 程序查询方式

CPU不断轮询检查I/O控制器中的“状态寄存器”，检测到状态为“已完成”之后，再从数据寄存器取出输入数据。CPU一直等待，无法执行其他程序

#### 程序终端方式

等待键盘I/O时CPU可以先去执行其他程序，键盘I/O完成后I/O控制器向CPU发出终端请求，CPU响应中断请求，并取走输入数据

数据流：键盘→I/O接口的数据寄存器→数据总线→CPU某寄存器→主存（程序变量的对应位置）

#### DMA控制方式

> 对于快速I/O设备（如磁盘），如果每准备好一个字就向CPU发出一次中断请求，则中断频率会过高，如何解决？

高速外设通过DMA接口（也是一种I/O接口）和DMA总线直接与主存交换数据。

DMA控制方式：主存与高速I/O设备之间有一条直接数据通路（DMA总线）。CPU向DMA接口发出“读/写”命令，并指明主存地址、磁盘地址、读写数据量等参数。

DMA控制器自动控制磁盘与主存的数据读写，每次读写占用一个存取周期。每完成一整块数据读写（如1KB为一整块），才向CPU发出一次中断请求。

#### 通道控制方式

通道是具有特殊功能的处理器，能对I/O设备进行统一管理。

通道可以识别并执行一系列通道指令，通道指令种类、功能通常比较单一。

通道执行完规定的任务后，再向CPU发出中断请求，之后CPU对中断进行处理。

### I/O系统的基本组成

- I/O硬件：包括外部设备、I/O接口、I/O总线等
- I/O软件：包括驱动程序、用户程序、管理程序、升级补丁等。通常采用I/O指令和通道指令实现主机和I/O设备的信息交换。
- I/O指令：是CPU指令的一部分，操作码（识别I/O指令）+命令码（对哪个设备进行操作）+设备码（做什么操作）
- 通道指令：通道能识别的命令。通道程序提前编制好放在主存中

## 7.2 输入输出设备

### 显示器

#### 显存

显示存储器VRAM：也称为刷新存储器，为了不断提高刷新图像的信号，必须把一帧图像信息存储在刷新存储器中。其存储容量由图像分辨率和灰度级决定，分辨率越高、灰度级越多，刷新存储器容量越大。

显存的理论最小值是一帧图像的大小。

VRAM容量=分辨率*灰度级位数

VRAM带宽=分辨率*灰度级位数*刷新频率

现代计算机中，显存除了作为当前显示帧的缓存，还会用于保存即将渲染的图像数据

#### 字符显示器

以点阵为基础。将字符点阵存入由ROM构成的字符发生器中，CRT控制器根据键盘I/O接口信息，从显存中找对应的ASCII码，再从字符发生器中读出相应字符的点阵，最后通过CRT显示

## 7.3 I/O接口

- 主机和外设之间的交接界面
- 实现主机和外设之间的信息交换
- 解决主机和外设之间信息形式和工作速度的差异问题

### I/O接口的功能

- 地址译码和设备选择
- 实现主机和外设之间的通信联络控制
- 数据缓冲
- 信号格式的转换。如电平转换、串/并转换或并/串转换、模/数转换或数/模转换等
- 传送控制命令和状态信息。

### I/O接口的工作原理

![image-20220721092537209](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x07%20IO%E7%B3%BB%E7%BB%9F/image-20220721092537209.png)

1. 主机通过数据线向**I/O控制寄存器**发送命令字/控制字
2. 主机从状态寄存器读取状态字，获得设备或I/O控制器的状态信息
3. 读/写数据：从数据缓冲寄存器发送或读取数据，完成主机与外设的数据交换

一个I/O接口可能连接多个I/O设备。这种情况下，每个设备都对应接口中的一组寄存器，操作不同的寄存器就是在操作不同的设备。

### I/O接口的类型

- 按数据传送方式
- 并行接口
- 串行接口
- 按主机访问I/O设备的控制方式
- 程序查询接口
- 中断接口
- DMA接口

### I/O端口及其编址

I/O接口中的各种寄存器称为**I/O端口**。

- 数据寄存器/端口：CPU能读写，通过数据线，实现CPU和外设之间的数据缓冲
- 状态寄存器/端口：CPU只能读，通过数据线，获取执行结果和设备的状态信息
- 控制寄存器/端口：CPU只能写，通过地址线和控制线写地址和命令，以便启动命令或更改设备模式

#### 统一编址/存储器映射方式

I/O端口当作存储器的单元进行地址分配。用统一的访存指令访问I/O端口。依靠**不同的地址码**区分内存和I/O设备

优点：不需要专门的I/O指令，程序设计灵活性高；端口有较大编址空间；读写控制逻辑电路简单

缺点：端口占用了主存地址空间；外设寻址时间长（地址位数多，地址译码速度变慢）

#### 独立编址/IO映射方式

I/O端口所用的地址单独编码。用专门的I/O指令访问I/O端口。

优点：使用专用I/O指令，程序编制清晰；I/O端口地址位数少，地址译码速度快；I/O端口的地址不占用主存地址空间

缺点：I/O指令类型少，一般只能对端口进行传送操作，程序设计灵活性差；需要CPU额外提供I/O设备读/写的控制信号，增加控制逻辑电路的复杂性。

## 7.4 控制方式

### 程序查询方式

![image-20220721164403974](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x07%20IO%E7%B3%BB%E7%BB%9F/image-20220721164403974.png)

1. CPU执行初始化程序，预置传送参数
2. 向I/O接口发出命令字，启动I/O设备
3. 从外设接口读取其状态信息
4. **CPU不断查询I/O设备状态**，直到外设准备就绪
5. 传送一次数据，修改地址和计数器参数
6. 判断传送是否结束，若未结束转第3步，直到计数器为0

特点：CPU“踏步”等待现象，CPU与I/O串行工作

优点：接口设计简单，设备量少

缺点：CPU在信息传送过程中花费大量时间查询和等待，且一段时间内只能与一台外设交换信息，效率大大降低

### 程序中断方式

![image-20220721164419267](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x07%20IO%E7%B3%BB%E7%BB%9F/image-20220721164419267.png)

#### 中断系统

- 中断的基本概念

在计算机执行现行程序的过程中，出现某些急需处理的异常情况或特殊请求，CPU暂时中止现行程序，转而处理这些异常情况或特殊请求。处理完毕后CPU自动返回到现行程序的断点处，继续执行原程序。

- 工作流程

- 中断请求：中断源向CPU发送中断请求信号

  - 若处于关中断状态，则不会响应任何中断请求
  - 关中断状态位存储在PSW寄存器中
  - 每个中断源都有一个**中断请求标记触发器**，当其状态为1时表示中断源有请求

- 中断响应判优

  - 中断请求标记：用专门的中断请求标记寄存器的各个位来区分不同的中断源
  - 中断判优：硬件排队器（硬件）或查询程序（软件）实现
  - 响应优先级（**在硬件线路上固定，不便改动**）
  - 不可屏蔽中断＞内部异常＞可屏蔽中断
  - 硬件故障＞软件中断
  - DMA中断＞I/O设备中断请求
  - 高速设备＞低速设备，输入设备＞输出设备，实时设备＞普通设备
  - 响应时间：**每条指令执行阶段的结束时刻（注：内部异常引发的中断不受此限制）**

- CPU响应中断的条件

  1. 中断源有中断请求
  2. CPU允许中断及开中断（异常和不可屏蔽中断不受限制）
  3. 一条指令执行完毕（异常不受限制），且没有更紧迫的任务

- 中断响应过程

  CPU响应中断后，需要进行一些操作，再转去中断服务程序。这些操作是由硬件直接实现的，称为**中断隐指令**。

  操作过程是：

  1. 关中断（允许中断触发器置0）。

  2. **保存断点**。**将PC和PSW内容这两种不可通过指令访问的信息**保存在栈或特定寄存器中。如果该中断是异常，则保存的PC地址是当前指令的地址；若是其他中断，则保存的是下一条指令的地址

  3. 引出中断服务程序。识别中断源，将对应的服务程序入口地址（中断向量）送入PC

     - 如何根据中断请求找到对应的中断服务程序的起始地址/入口地址？

     硬件向量法：给中断请求一个编号，中断向量地址形成部件根据中断请求产生对应的向量地址，再由向量地址在主存中找到对应的跳转指令，该跳转指令的地址码就是中断服务程序的入口地址，也称中断向量。

     所以**中断向量**是个地址，而**中断向量地址**是地址的地址，两者是不同的。

- 中断处理过程

  1. 进入中断服务程序后，首先**通过指令保存现场和中断屏蔽字**
  2. 开中断（允许中断触发器置1）。允许更高级中断请求得到响应，实现中断嵌套
  3. 执行中断服务程序
  4. 关中断。避免恢复现场和屏蔽字时被打断
  5. 恢复现场和屏蔽字
  6. 开中断、中断返回

- 多重中断

- 又称为中断嵌套，即在中断服务程序执行过程中又被中断，转去执行其他的中断服务程序。

- 中断屏蔽字：虽然有多重中断，但是如果处理高速I/O的中断被处理低速I/O的中断打断了，优先处理低速I/O的中断的话，显然是不科学的。故不同类型的中断应屏蔽掉优先级比它更低的中断请求，以免被它们打断。这就用到了中断屏蔽字。

  中断屏蔽字中，1表示屏蔽，0表示正常申请。因此一个中断源的屏蔽字中1越多，表明这个中断源的优先级越高。且每个屏蔽字中至少要有一个1（屏蔽掉同种中断源的中断）

#### 例题

![image-20220721110534407](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x07%20IO%E7%B3%BB%E7%BB%9F/image-20220721110534407.png)

一个时钟周期为$\frac{1}{50\times 10^6}=20ns$，完成任务所需的时间为$1000\times(10+20\times4+0.5ms/20ns)=1000\times(10+80+25000)=25090000$个时钟周期

CPU用于该任务的时间为$1000\times(10+80)=9\times10^4$个时钟周期

### DMA方式

![image-20220721164509242](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x07%20IO%E7%B3%BB%E7%BB%9F/image-20220721164509242.png)

直接在外设与内存之间开辟一条“直接数据通道”

数据传送不经过CPU，不需要保护、恢复CPU现场等操作

在数据准备阶段，CPU与外设并行工作

#### DMA控制器的组成

1. 主存地址计数器：存放要交换数据的主存地址
2. 传送长度计数器：记录要传送数据的长度，计数溢出时数据传送完毕，自动发中断请求
3. 数据缓冲寄存器：暂存每次传送的数据
4. DMA请求触发器：每当I/O设备准备好数据后，给出一个控制信号，使DMA请求触发器置位
5. “控制/状态”逻辑：由控制和时序电路及状态标志组成，用于指定传送方向，修改传送参数，并对DMA请求信号、CPU响应信号进行协调与同步
6. 中断机构：当一个数据块传送完毕后触发中断机构，向CPU提出中断请求

#### DMA工作流程

1. CPU向DMA控制器指明要输入还是输出；要传送多少个数据
2. DMA控制器接受**外设发出的DMA请求**，并向CPU发出总线请求
3. CPU响应此总线请求，发出总线响应信号，接管总线控制权，进入DMA操作周期
4. 确定传送数据的主存单元地址及长度，并能自动修改主存地址计数和传送长度计数
5. DMA控制器规定数据在主存和外设间的传送方向（实际上是CPU告诉的），发出读写等控制信号，执行数据传送操作
6. 向CPU报告DMA操作的结束

#### DMA传送过程

1. 预处理
2. 主存起始地址→AR（DMA内的主存地址计数器）
3. I/O设备地址→DAR（存储要访问的数据在I/O设备中的地址）
4. 传送数据个数→WC（DMA内的传送长度计数器）
5. 启动I/O设备
6. 数据传送
7. CPU继续执行主程序
8. DMA控制器允许I/O设备将数据写入数据缓冲寄存器DR，当DR写满后，DMA请求触发器向DMA控制/状态逻辑发送DMA请求，再有DMA控制/状态逻辑向总线发送总线请求
9. DMA控制器将数据缓冲寄存器中的数据写入主存。
10. 后处理
11. 需要读写的I/O数据全部读写完毕，DMA控制器通过中断机构向CPU发出中断请求
12. 做DMA结束处理：如校验送入主存的数据是否正确、决定是否继续用DMA传送其他数据块等

注意：

- 每写满一次DR，才发出一次DMA请求，将DR中的数据写入主存
- 全部数据都写入主存后，DMA控制器才向CPU发出中断请求

#### DMA传送方式

当I/O设备与CPU同时访问主存时，可能发生冲突，因此需要规定访问方式。

1. 停止CPU访问主存

当DMA控制并使用主存时，禁止CPU访问主存

![image-20221026113447919](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x07%20IO%E7%B3%BB%E7%BB%9F/image-20221026113447919.png)

1. DMA与CPU交替访存

一个CPU周期，分为C1和C2两个周期。C1专供DMA访存，C2专供CPU访存

把访存时间固定。不需要总线使用权的申请、建立和归还

![image-20221026113512709](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x07%20IO%E7%B3%BB%E7%BB%9F/image-20221026113512709.png)

1. 周期挪用（周期窃取）

若I/O设备需要访存时，CPU正在访存：则等待存取周期结束让出总线

若CPU与DMA同时请求访存：则I/O访存优先，因为I/O不立即访存就可能丢失数据，此时挪用一个或几个存取周期，传送完一个数据后立即释放总线。

因为这导致了CPU在一个指令周期内部的存取周期不得不延后开始，所以为周期挪用

![image-20221026113500505](https://streamazure.github.io/Computer_Basics_Notes/Computer_Organization_Notes/0x07%20IO%E7%B3%BB%E7%BB%9F/image-20221026113500505.png)

#### DMA方式与程序中断方式

|          | 程序中断                              | DMA                                             |
| :------- | :------------------------------------ | :---------------------------------------------- |
| 数据传送 | 程序控制（程序的切换→保存和恢复现场） | 硬件控制（CPU只需进行预处理和后处理）           |
| 中断请求 | 传送数据                              | 后处理                                          |
| 响应     | 指令执行周期结束后响应中断            | 每个机器周期结束均可，总线空闲时即可响应DMA请求 |
| 场景     | CPU控制，低速设备                     | DMA控制器控制，高速设备                         |
| 优先级   | 优先级低于DMA                         | 优先级高于中断                                  |
| 异常处理 | 能处理异常事件                        | 仅传送数据                                      |

